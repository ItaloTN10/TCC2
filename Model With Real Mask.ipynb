{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "classified-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-passion",
   "metadata": {},
   "source": [
    "# Pr√©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-drove",
   "metadata": {},
   "source": [
    "### Carregar Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "contemporary-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_size = 160\n",
    "\n",
    "def select_image(filename):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    \n",
    "    old_size = image.size\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    \n",
    "    image = image.resize(new_size,Image.ANTIALIAS)\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_im.paste(image, ((desired_size-new_size[0])//2,\n",
    "                    (desired_size-new_size[1])//2))\n",
    "    \n",
    "    # convert to array\n",
    "    return np.asarray(new_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-grant",
   "metadata": {},
   "source": [
    "### Criar Dataset Personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attended-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(directory, subdir, imagens, labels):\n",
    "    \n",
    "\n",
    "    for filename in listdir(directory):\n",
    "\n",
    "        path = directory + filename\n",
    "\n",
    "        try:\n",
    "            imagens.append(select_image(path))\n",
    "            labels.append(subdir)\n",
    "        except:\n",
    "            print(\"Erro ao ler imagem {}\".format(path))\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-arrival",
   "metadata": {},
   "source": [
    "### Selecionar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "measured-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_set(directory):\n",
    "\n",
    "    imagens = list()\n",
    "    labels = list()\n",
    "\n",
    "    for subdir in listdir(directory):\n",
    "        # path\n",
    "        path = directory + subdir + '/'\n",
    "        \n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        imagens, labels = load_classes(path, subdir, imagens, labels)\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dangerous-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r\"/dataset/\"\n",
    "imagens, labels  = select_data_set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "associate-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens_array = np.array(imagens) / 255.0  ## convertendo de lista para array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improved-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.array(labels)  ## convertendo de lista para array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "settled-determination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6542, 160, 160, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automatic-credits",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6542,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-shelter",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "corporate-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "labels_array = lb.fit_transform(labels_array)\n",
    "labels_array = to_categorical(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abstract-pizza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6542, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-milton",
   "metadata": {},
   "source": [
    "## Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distinguished-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size   = 128\n",
    "input_shape  = (160, 160, 3)\n",
    "random_state = 42\n",
    "alpha        = 1e-5\n",
    "epoch        = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-apple",
   "metadata": {},
   "source": [
    "## CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "favorite-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bottom-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"face.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "changed-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, min_delta=alpha, patience=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moved-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, lr_reduce]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "greatest-starter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/italo/anaconda3/envs/gputest/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "nsamples, nx, ny, nz = imagens_array.shape\n",
    "imagens_array = imagens_array.reshape((nsamples,nx*ny*nz))\n",
    "sm = SMOTE(random_state=random_state)\n",
    "imagens_array, labels_array = sm.fit_resample(imagens_array, labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accepting-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, n = imagens_array.shape\n",
    "imagens_array = imagens_array.reshape(nsamples, nx, ny, nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "large-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9240, 160, 160, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagens_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "appropriate-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(imagens_array, labels_array, test_size=0.20, random_state=random_state)\n",
    "del imagens_array\n",
    "del imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-genetics",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "polish-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        horizontal_flip= True,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "train_datagen.fit(trainX)\n",
    "\n",
    "data_aug = train_datagen.flow(trainX, trainY, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-lewis",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "nervous-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "raising-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 160, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 160, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 80, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 40, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 20, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-spank",
   "metadata": {},
   "source": [
    "## Retreinando parte da VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alert-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block4_conv1':\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tired-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 160, 160, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 160, 160, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 80, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 80, 80, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 40, 40, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 40, 40, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 20, 20, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 20, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 12,979,200\n",
      "Non-trainable params: 1,735,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-vietnamese",
   "metadata": {},
   "source": [
    "## Criando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beautiful-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu',input_dim=512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(30, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "virgin-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 5, 5, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 16,307,550\n",
      "Trainable params: 14,571,038\n",
      "Non-trainable params: 1,736,512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-philosophy",
   "metadata": {},
   "source": [
    "## Compilar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "agreed-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "plain-astronomy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 3.4167 - accuracy: 0.0413\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03247, saving model to face.h5\n",
      "57/57 [==============================] - 70s 1s/step - loss: 3.4167 - accuracy: 0.0413 - val_loss: 11.4391 - val_accuracy: 0.0325 - lr: 0.0010\n",
      "Epoch 2/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 3.2712 - accuracy: 0.0571\n",
      "Epoch 00002: val_accuracy improved from 0.03247 to 0.03571, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 3.2712 - accuracy: 0.0571 - val_loss: 6.1460 - val_accuracy: 0.0357 - lr: 0.0010\n",
      "Epoch 3/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 3.1008 - accuracy: 0.0611\n",
      "Epoch 00003: val_accuracy improved from 0.03571 to 0.06439, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 3.1008 - accuracy: 0.0611 - val_loss: 3.1422 - val_accuracy: 0.0644 - lr: 0.0010\n",
      "Epoch 4/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.9911 - accuracy: 0.0681\n",
      "Epoch 00004: val_accuracy improved from 0.06439 to 0.06710, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.9911 - accuracy: 0.0681 - val_loss: 2.9944 - val_accuracy: 0.0671 - lr: 0.0010\n",
      "Epoch 5/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.9252 - accuracy: 0.0759\n",
      "Epoch 00005: val_accuracy improved from 0.06710 to 0.08009, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.9252 - accuracy: 0.0759 - val_loss: 2.9719 - val_accuracy: 0.0801 - lr: 0.0010\n",
      "Epoch 6/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.8741 - accuracy: 0.0856\n",
      "Epoch 00006: val_accuracy improved from 0.08009 to 0.08225, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.8741 - accuracy: 0.0856 - val_loss: 2.9738 - val_accuracy: 0.0823 - lr: 0.0010\n",
      "Epoch 7/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.8462 - accuracy: 0.0982\n",
      "Epoch 00007: val_accuracy did not improve from 0.08225\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.8462 - accuracy: 0.0982 - val_loss: 6.3259 - val_accuracy: 0.0292 - lr: 0.0010\n",
      "Epoch 8/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.8300 - accuracy: 0.0933\n",
      "Epoch 00008: val_accuracy did not improve from 0.08225\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.8300 - accuracy: 0.0933 - val_loss: 2.9856 - val_accuracy: 0.0676 - lr: 0.0010\n",
      "Epoch 9/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.7983 - accuracy: 0.0988\n",
      "Epoch 00009: val_accuracy did not improve from 0.08225\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.7983 - accuracy: 0.0988 - val_loss: 77.2420 - val_accuracy: 0.0335 - lr: 0.0010\n",
      "Epoch 10/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.7915 - accuracy: 0.1048\n",
      "Epoch 00010: val_accuracy did not improve from 0.08225\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.7915 - accuracy: 0.1048 - val_loss: 3.3164 - val_accuracy: 0.0639 - lr: 0.0010\n",
      "Epoch 11/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.7399 - accuracy: 0.1121\n",
      "Epoch 00011: val_accuracy improved from 0.08225 to 0.11580, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.7399 - accuracy: 0.1121 - val_loss: 2.7381 - val_accuracy: 0.1158 - lr: 0.0010\n",
      "Epoch 12/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.6828 - accuracy: 0.1271\n",
      "Epoch 00012: val_accuracy did not improve from 0.11580\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.6828 - accuracy: 0.1271 - val_loss: 4.4183 - val_accuracy: 0.0644 - lr: 0.0010\n",
      "Epoch 13/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.6394 - accuracy: 0.1373\n",
      "Epoch 00013: val_accuracy did not improve from 0.11580\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.6394 - accuracy: 0.1373 - val_loss: 3.2736 - val_accuracy: 0.0931 - lr: 0.0010\n",
      "Epoch 14/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.6249 - accuracy: 0.1350\n",
      "Epoch 00014: val_accuracy did not improve from 0.11580\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.6249 - accuracy: 0.1350 - val_loss: 6.4460 - val_accuracy: 0.0714 - lr: 0.0010\n",
      "Epoch 15/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.5993 - accuracy: 0.1384\n",
      "Epoch 00015: val_accuracy improved from 0.11580 to 0.12067, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.5993 - accuracy: 0.1384 - val_loss: 2.6386 - val_accuracy: 0.1207 - lr: 0.0010\n",
      "Epoch 16/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.5884 - accuracy: 0.1444\n",
      "Epoch 00016: val_accuracy did not improve from 0.12067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.5884 - accuracy: 0.1444 - val_loss: 2.8924 - val_accuracy: 0.0882 - lr: 0.0010\n",
      "Epoch 17/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.5400 - accuracy: 0.1542\n",
      "Epoch 00017: val_accuracy improved from 0.12067 to 0.12987, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.5400 - accuracy: 0.1542 - val_loss: 2.6541 - val_accuracy: 0.1299 - lr: 0.0010\n",
      "Epoch 18/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.5262 - accuracy: 0.1569\n",
      "Epoch 00018: val_accuracy did not improve from 0.12987\n",
      "57/57 [==============================] - 64s 1s/step - loss: 2.5262 - accuracy: 0.1569 - val_loss: 4.6145 - val_accuracy: 0.0714 - lr: 0.0010\n",
      "Epoch 19/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.5001 - accuracy: 0.1730\n",
      "Epoch 00019: val_accuracy improved from 0.12987 to 0.14556, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.5001 - accuracy: 0.1730 - val_loss: 2.6093 - val_accuracy: 0.1456 - lr: 0.0010\n",
      "Epoch 20/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.4424 - accuracy: 0.1843\n",
      "Epoch 00020: val_accuracy improved from 0.14556 to 0.14665, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.4424 - accuracy: 0.1843 - val_loss: 2.7260 - val_accuracy: 0.1466 - lr: 0.0010\n",
      "Epoch 21/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.4206 - accuracy: 0.1948\n",
      "Epoch 00021: val_accuracy improved from 0.14665 to 0.20942, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.4206 - accuracy: 0.1948 - val_loss: 2.3748 - val_accuracy: 0.2094 - lr: 0.0010\n",
      "Epoch 22/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.3705 - accuracy: 0.2108\n",
      "Epoch 00022: val_accuracy did not improve from 0.20942\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.3705 - accuracy: 0.2108 - val_loss: 2.7975 - val_accuracy: 0.1558 - lr: 0.0010\n",
      "Epoch 23/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.3087 - accuracy: 0.2227\n",
      "Epoch 00023: val_accuracy improved from 0.20942 to 0.23647, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.3087 - accuracy: 0.2227 - val_loss: 2.2794 - val_accuracy: 0.2365 - lr: 0.0010\n",
      "Epoch 24/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.2942 - accuracy: 0.2233\n",
      "Epoch 00024: val_accuracy did not improve from 0.23647\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.2942 - accuracy: 0.2233 - val_loss: 2.8325 - val_accuracy: 0.1596 - lr: 0.0010\n",
      "Epoch 25/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.2774 - accuracy: 0.2404\n",
      "Epoch 00025: val_accuracy improved from 0.23647 to 0.24567, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 2.2774 - accuracy: 0.2404 - val_loss: 2.2855 - val_accuracy: 0.2457 - lr: 0.0010\n",
      "Epoch 26/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.2338 - accuracy: 0.2479\n",
      "Epoch 00026: val_accuracy did not improve from 0.24567\n",
      "57/57 [==============================] - 63s 1s/step - loss: 2.2338 - accuracy: 0.2479 - val_loss: 2.3473 - val_accuracy: 0.2321 - lr: 0.0010\n",
      "Epoch 27/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.1884 - accuracy: 0.2649\n",
      "Epoch 00027: val_accuracy improved from 0.24567 to 0.27976, saving model to face.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 62s 1s/step - loss: 2.1884 - accuracy: 0.2649 - val_loss: 2.1426 - val_accuracy: 0.2798 - lr: 0.0010\n",
      "Epoch 28/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.1782 - accuracy: 0.2713\n",
      "Epoch 00028: val_accuracy did not improve from 0.27976\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.1782 - accuracy: 0.2713 - val_loss: 2.2888 - val_accuracy: 0.2505 - lr: 0.0010\n",
      "Epoch 29/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.1586 - accuracy: 0.2778\n",
      "Epoch 00029: val_accuracy improved from 0.27976 to 0.32900, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.1586 - accuracy: 0.2778 - val_loss: 2.0039 - val_accuracy: 0.3290 - lr: 0.0010\n",
      "Epoch 30/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.1252 - accuracy: 0.2998\n",
      "Epoch 00030: val_accuracy did not improve from 0.32900\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.1252 - accuracy: 0.2998 - val_loss: 2.2405 - val_accuracy: 0.2689 - lr: 0.0010\n",
      "Epoch 31/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.0813 - accuracy: 0.3081\n",
      "Epoch 00031: val_accuracy did not improve from 0.32900\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.0813 - accuracy: 0.3081 - val_loss: 3.2315 - val_accuracy: 0.1699 - lr: 0.0010\n",
      "Epoch 32/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 2.0520 - accuracy: 0.3166\n",
      "Epoch 00032: val_accuracy improved from 0.32900 to 0.34524, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 2.0520 - accuracy: 0.3166 - val_loss: 1.9677 - val_accuracy: 0.3452 - lr: 0.0010\n",
      "Epoch 33/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.9940 - accuracy: 0.3232\n",
      "Epoch 00033: val_accuracy did not improve from 0.34524\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.9940 - accuracy: 0.3232 - val_loss: 1.9866 - val_accuracy: 0.3436 - lr: 0.0010\n",
      "Epoch 34/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.9784 - accuracy: 0.3502\n",
      "Epoch 00034: val_accuracy did not improve from 0.34524\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.9784 - accuracy: 0.3502 - val_loss: 2.1740 - val_accuracy: 0.2960 - lr: 0.0010\n",
      "Epoch 35/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.9621 - accuracy: 0.3491\n",
      "Epoch 00035: val_accuracy improved from 0.34524 to 0.35931, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.9621 - accuracy: 0.3491 - val_loss: 1.8907 - val_accuracy: 0.3593 - lr: 0.0010\n",
      "Epoch 36/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.9052 - accuracy: 0.3648\n",
      "Epoch 00036: val_accuracy did not improve from 0.35931\n",
      "57/57 [==============================] - 61s 1s/step - loss: 1.9052 - accuracy: 0.3648 - val_loss: 1.9558 - val_accuracy: 0.3371 - lr: 0.0010\n",
      "Epoch 37/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.8680 - accuracy: 0.3747\n",
      "Epoch 00037: val_accuracy did not improve from 0.35931\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.8680 - accuracy: 0.3747 - val_loss: 2.1473 - val_accuracy: 0.2938 - lr: 0.0010\n",
      "Epoch 38/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.8513 - accuracy: 0.3800\n",
      "Epoch 00038: val_accuracy did not improve from 0.35931\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.8513 - accuracy: 0.3800 - val_loss: 2.0137 - val_accuracy: 0.3350 - lr: 0.0010\n",
      "Epoch 39/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.8484 - accuracy: 0.3824\n",
      "Epoch 00039: val_accuracy did not improve from 0.35931\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.8484 - accuracy: 0.3824 - val_loss: 2.8854 - val_accuracy: 0.2045 - lr: 0.0010\n",
      "Epoch 40/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.8116 - accuracy: 0.3948\n",
      "Epoch 00040: val_accuracy did not improve from 0.35931\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.8116 - accuracy: 0.3948 - val_loss: 2.3133 - val_accuracy: 0.3171 - lr: 0.0010\n",
      "Epoch 41/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.7870 - accuracy: 0.3976\n",
      "Epoch 00041: val_accuracy improved from 0.35931 to 0.44210, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.7870 - accuracy: 0.3976 - val_loss: 1.7094 - val_accuracy: 0.4421 - lr: 0.0010\n",
      "Epoch 42/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.7332 - accuracy: 0.4196\n",
      "Epoch 00042: val_accuracy did not improve from 0.44210\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.7332 - accuracy: 0.4196 - val_loss: 1.7629 - val_accuracy: 0.3972 - lr: 0.0010\n",
      "Epoch 43/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.7151 - accuracy: 0.4236\n",
      "Epoch 00043: val_accuracy did not improve from 0.44210\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.7151 - accuracy: 0.4236 - val_loss: 2.0003 - val_accuracy: 0.3561 - lr: 0.0010\n",
      "Epoch 44/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.6790 - accuracy: 0.4393\n",
      "Epoch 00044: val_accuracy improved from 0.44210 to 0.46266, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.6790 - accuracy: 0.4393 - val_loss: 1.6414 - val_accuracy: 0.4627 - lr: 0.0010\n",
      "Epoch 45/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.7722 - accuracy: 0.4224\n",
      "Epoch 00045: val_accuracy did not improve from 0.46266\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.7722 - accuracy: 0.4224 - val_loss: 1.7735 - val_accuracy: 0.4188 - lr: 0.0010\n",
      "Epoch 46/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.6692 - accuracy: 0.4529\n",
      "Epoch 00046: val_accuracy did not improve from 0.46266\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.6692 - accuracy: 0.4529 - val_loss: 1.7748 - val_accuracy: 0.4421 - lr: 0.0010\n",
      "Epoch 47/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.6221 - accuracy: 0.4576\n",
      "Epoch 00047: val_accuracy improved from 0.46266 to 0.47619, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.6221 - accuracy: 0.4576 - val_loss: 1.5902 - val_accuracy: 0.4762 - lr: 0.0010\n",
      "Epoch 48/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.5828 - accuracy: 0.4730\n",
      "Epoch 00048: val_accuracy improved from 0.47619 to 0.49080, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.5828 - accuracy: 0.4730 - val_loss: 1.5226 - val_accuracy: 0.4908 - lr: 0.0010\n",
      "Epoch 49/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.5919 - accuracy: 0.4800\n",
      "Epoch 00049: val_accuracy did not improve from 0.49080\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.5919 - accuracy: 0.4800 - val_loss: 1.6768 - val_accuracy: 0.4405 - lr: 0.0010\n",
      "Epoch 50/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.5123 - accuracy: 0.5025\n",
      "Epoch 00050: val_accuracy did not improve from 0.49080\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.5123 - accuracy: 0.5025 - val_loss: 1.6979 - val_accuracy: 0.4491 - lr: 0.0010\n",
      "Epoch 51/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.5089 - accuracy: 0.5088\n",
      "Epoch 00051: val_accuracy did not improve from 0.49080\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.5089 - accuracy: 0.5088 - val_loss: 1.5760 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 52/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.4781 - accuracy: 0.5131\n",
      "Epoch 00052: val_accuracy did not improve from 0.49080\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.4781 - accuracy: 0.5131 - val_loss: 1.6355 - val_accuracy: 0.4621 - lr: 0.0010\n",
      "Epoch 53/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.4334 - accuracy: 0.5311\n",
      "Epoch 00053: val_accuracy improved from 0.49080 to 0.53950, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.4334 - accuracy: 0.5311 - val_loss: 1.4998 - val_accuracy: 0.5395 - lr: 0.0010\n",
      "Epoch 54/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.4093 - accuracy: 0.5450\n",
      "Epoch 00054: val_accuracy did not improve from 0.53950\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.4093 - accuracy: 0.5450 - val_loss: 1.4982 - val_accuracy: 0.4930 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.3805 - accuracy: 0.5486\n",
      "Epoch 00055: val_accuracy did not improve from 0.53950\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.3805 - accuracy: 0.5486 - val_loss: 1.6499 - val_accuracy: 0.5070 - lr: 0.0010\n",
      "Epoch 56/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.3740 - accuracy: 0.5581\n",
      "Epoch 00056: val_accuracy did not improve from 0.53950\n",
      "57/57 [==============================] - 61s 1s/step - loss: 1.3740 - accuracy: 0.5581 - val_loss: 1.7159 - val_accuracy: 0.4545 - lr: 0.0010\n",
      "Epoch 57/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.3439 - accuracy: 0.5699\n",
      "Epoch 00057: val_accuracy did not improve from 0.53950\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.3439 - accuracy: 0.5699 - val_loss: 1.5448 - val_accuracy: 0.4973 - lr: 0.0010\n",
      "Epoch 58/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.3038 - accuracy: 0.5830\n",
      "Epoch 00058: val_accuracy did not improve from 0.53950\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.3038 - accuracy: 0.5830 - val_loss: 1.4568 - val_accuracy: 0.5179 - lr: 0.0010\n",
      "Epoch 59/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.2853 - accuracy: 0.6005\n",
      "Epoch 00059: val_accuracy improved from 0.53950 to 0.58766, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.2853 - accuracy: 0.6005 - val_loss: 1.4509 - val_accuracy: 0.5877 - lr: 0.0010\n",
      "Epoch 60/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.2729 - accuracy: 0.6060\n",
      "Epoch 00060: val_accuracy did not improve from 0.58766\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.2729 - accuracy: 0.6060 - val_loss: 1.4824 - val_accuracy: 0.5519 - lr: 0.0010\n",
      "Epoch 61/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.2095 - accuracy: 0.6213\n",
      "Epoch 00061: val_accuracy did not improve from 0.58766\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.2095 - accuracy: 0.6213 - val_loss: 1.4038 - val_accuracy: 0.5741 - lr: 0.0010\n",
      "Epoch 62/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.1589 - accuracy: 0.6377\n",
      "Epoch 00062: val_accuracy improved from 0.58766 to 0.63258, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.1589 - accuracy: 0.6377 - val_loss: 1.1968 - val_accuracy: 0.6326 - lr: 0.0010\n",
      "Epoch 63/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.1539 - accuracy: 0.6448\n",
      "Epoch 00063: val_accuracy did not improve from 0.63258\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.1539 - accuracy: 0.6448 - val_loss: 1.3896 - val_accuracy: 0.5963 - lr: 0.0010\n",
      "Epoch 64/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.1146 - accuracy: 0.6523\n",
      "Epoch 00064: val_accuracy improved from 0.63258 to 0.64881, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.1146 - accuracy: 0.6523 - val_loss: 1.2124 - val_accuracy: 0.6488 - lr: 0.0010\n",
      "Epoch 65/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.6593\n",
      "Epoch 00065: val_accuracy did not improve from 0.64881\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.0773 - accuracy: 0.6593 - val_loss: 1.2431 - val_accuracy: 0.6369 - lr: 0.0010\n",
      "Epoch 66/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0684 - accuracy: 0.6635\n",
      "Epoch 00066: val_accuracy did not improve from 0.64881\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.0684 - accuracy: 0.6635 - val_loss: 1.2010 - val_accuracy: 0.6450 - lr: 0.0010\n",
      "Epoch 67/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0555 - accuracy: 0.6737\n",
      "Epoch 00067: val_accuracy did not improve from 0.64881\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.0555 - accuracy: 0.6737 - val_loss: 1.2457 - val_accuracy: 0.6423 - lr: 0.0010\n",
      "Epoch 68/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.6868\n",
      "Epoch 00068: val_accuracy did not improve from 0.64881\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.0061 - accuracy: 0.6868 - val_loss: 1.3998 - val_accuracy: 0.6104 - lr: 0.0010\n",
      "Epoch 69/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0061 - accuracy: 0.6854\n",
      "Epoch 00069: val_accuracy improved from 0.64881 to 0.66071, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.0061 - accuracy: 0.6854 - val_loss: 1.1927 - val_accuracy: 0.6607 - lr: 0.0010\n",
      "Epoch 70/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 1.0056 - accuracy: 0.6869\n",
      "Epoch 00070: val_accuracy did not improve from 0.66071\n",
      "57/57 [==============================] - 60s 1s/step - loss: 1.0056 - accuracy: 0.6869 - val_loss: 1.2716 - val_accuracy: 0.6342 - lr: 0.0010\n",
      "Epoch 71/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.7212\n",
      "Epoch 00071: val_accuracy improved from 0.66071 to 0.67587, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.9342 - accuracy: 0.7212 - val_loss: 1.0585 - val_accuracy: 0.6759 - lr: 0.0010\n",
      "Epoch 72/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.9461 - accuracy: 0.7112\n",
      "Epoch 00072: val_accuracy improved from 0.67587 to 0.68939, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.9461 - accuracy: 0.7112 - val_loss: 1.0567 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 73/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.7244\n",
      "Epoch 00073: val_accuracy did not improve from 0.68939\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.9070 - accuracy: 0.7244 - val_loss: 1.1417 - val_accuracy: 0.6894 - lr: 0.0010\n",
      "Epoch 74/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.8796 - accuracy: 0.7372\n",
      "Epoch 00074: val_accuracy did not improve from 0.68939\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.8796 - accuracy: 0.7372 - val_loss: 1.5465 - val_accuracy: 0.5763 - lr: 0.0010\n",
      "Epoch 75/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.8648 - accuracy: 0.7460\n",
      "Epoch 00075: val_accuracy did not improve from 0.68939\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.8648 - accuracy: 0.7460 - val_loss: 1.1463 - val_accuracy: 0.6656 - lr: 0.0010\n",
      "Epoch 76/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.8620 - accuracy: 0.7428\n",
      "Epoch 00076: val_accuracy improved from 0.68939 to 0.69426, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.8620 - accuracy: 0.7428 - val_loss: 1.0453 - val_accuracy: 0.6943 - lr: 0.0010\n",
      "Epoch 77/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.7493\n",
      "Epoch 00077: val_accuracy improved from 0.69426 to 0.71537, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.8537 - accuracy: 0.7493 - val_loss: 0.9970 - val_accuracy: 0.7154 - lr: 0.0010\n",
      "Epoch 78/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.8427 - accuracy: 0.7518\n",
      "Epoch 00078: val_accuracy did not improve from 0.71537\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.8427 - accuracy: 0.7518 - val_loss: 1.0544 - val_accuracy: 0.7083 - lr: 0.0010\n",
      "Epoch 79/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.8331 - accuracy: 0.7541\n",
      "Epoch 00079: val_accuracy did not improve from 0.71537\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.8331 - accuracy: 0.7541 - val_loss: 1.0647 - val_accuracy: 0.6899 - lr: 0.0010\n",
      "Epoch 80/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.7999 - accuracy: 0.7687\n",
      "Epoch 00080: val_accuracy did not improve from 0.71537\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.7999 - accuracy: 0.7687 - val_loss: 1.2122 - val_accuracy: 0.6851 - lr: 0.0010\n",
      "Epoch 81/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.7897 - accuracy: 0.7668\n",
      "Epoch 00081: val_accuracy did not improve from 0.71537\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.7897 - accuracy: 0.7668 - val_loss: 1.7096 - val_accuracy: 0.6012 - lr: 0.0010\n",
      "Epoch 82/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.7684 - accuracy: 0.7746\n",
      "Epoch 00082: val_accuracy did not improve from 0.71537\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.7684 - accuracy: 0.7746 - val_loss: 1.0912 - val_accuracy: 0.7127 - lr: 0.0010\n",
      "Epoch 83/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.7877\n",
      "Epoch 00083: val_accuracy improved from 0.71537 to 0.73593, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.7200 - accuracy: 0.7877 - val_loss: 1.0221 - val_accuracy: 0.7359 - lr: 0.0010\n",
      "Epoch 84/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.7916\n",
      "Epoch 00084: val_accuracy did not improve from 0.73593\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.6960 - accuracy: 0.7916 - val_loss: 1.0915 - val_accuracy: 0.7213 - lr: 0.0010\n",
      "Epoch 85/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.7215 - accuracy: 0.7936\n",
      "Epoch 00085: val_accuracy did not improve from 0.73593\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.7215 - accuracy: 0.7936 - val_loss: 1.1569 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 86/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.7932\n",
      "Epoch 00086: val_accuracy did not improve from 0.73593\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.7044 - accuracy: 0.7932 - val_loss: 2.0091 - val_accuracy: 0.4594 - lr: 0.0010\n",
      "Epoch 87/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.8007\n",
      "Epoch 00087: val_accuracy did not improve from 0.73593\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.6902 - accuracy: 0.8007 - val_loss: 1.0351 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 88/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6677 - accuracy: 0.8066\n",
      "Epoch 00088: val_accuracy did not improve from 0.73593\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.6677 - accuracy: 0.8066 - val_loss: 1.1567 - val_accuracy: 0.6997 - lr: 0.0010\n",
      "Epoch 89/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.8190\n",
      "Epoch 00089: val_accuracy improved from 0.73593 to 0.74784, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.6512 - accuracy: 0.8190 - val_loss: 0.9804 - val_accuracy: 0.7478 - lr: 0.0010\n",
      "Epoch 90/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.8165\n",
      "Epoch 00090: val_accuracy did not improve from 0.74784\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.6351 - accuracy: 0.8165 - val_loss: 1.1851 - val_accuracy: 0.7062 - lr: 0.0010\n",
      "Epoch 91/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.8270\n",
      "Epoch 00091: val_accuracy improved from 0.74784 to 0.78193, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.6330 - accuracy: 0.8270 - val_loss: 0.8426 - val_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 92/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.8237\n",
      "Epoch 00092: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.6268 - accuracy: 0.8237 - val_loss: 0.9941 - val_accuracy: 0.7051 - lr: 0.0010\n",
      "Epoch 93/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.8318\n",
      "Epoch 00093: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5913 - accuracy: 0.8318 - val_loss: 0.9990 - val_accuracy: 0.7597 - lr: 0.0010\n",
      "Epoch 94/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.8429\n",
      "Epoch 00094: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.5709 - accuracy: 0.8429 - val_loss: 1.0363 - val_accuracy: 0.7435 - lr: 0.0010\n",
      "Epoch 95/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.8413\n",
      "Epoch 00095: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5565 - accuracy: 0.8413 - val_loss: 0.9058 - val_accuracy: 0.7771 - lr: 0.0010\n",
      "Epoch 96/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.8429\n",
      "Epoch 00096: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5652 - accuracy: 0.8429 - val_loss: 0.8991 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 97/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5625 - accuracy: 0.8417\n",
      "Epoch 00097: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5625 - accuracy: 0.8417 - val_loss: 1.0770 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 98/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5154 - accuracy: 0.8566\n",
      "Epoch 00098: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5154 - accuracy: 0.8566 - val_loss: 1.0853 - val_accuracy: 0.7538 - lr: 0.0010\n",
      "Epoch 99/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8491\n",
      "Epoch 00099: val_accuracy did not improve from 0.78193\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5448 - accuracy: 0.8491 - val_loss: 1.1225 - val_accuracy: 0.7386 - lr: 0.0010\n",
      "Epoch 100/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.8520\n",
      "Epoch 00100: val_accuracy improved from 0.78193 to 0.78680, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5442 - accuracy: 0.8520 - val_loss: 0.9071 - val_accuracy: 0.7868 - lr: 0.0010\n",
      "Epoch 101/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.8535\n",
      "Epoch 00101: val_accuracy did not improve from 0.78680\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5408 - accuracy: 0.8535 - val_loss: 0.9644 - val_accuracy: 0.7619 - lr: 0.0010\n",
      "Epoch 102/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8583\n",
      "Epoch 00102: val_accuracy did not improve from 0.78680\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5280 - accuracy: 0.8583 - val_loss: 0.9668 - val_accuracy: 0.7787 - lr: 0.0010\n",
      "Epoch 103/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.8662\n",
      "Epoch 00103: val_accuracy improved from 0.78680 to 0.80141, saving model to face.h5\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.4932 - accuracy: 0.8662 - val_loss: 0.8277 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Epoch 104/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.8623\n",
      "Epoch 00104: val_accuracy did not improve from 0.80141\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.5005 - accuracy: 0.8623 - val_loss: 0.7900 - val_accuracy: 0.7938 - lr: 0.0010\n",
      "Epoch 105/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.8718\n",
      "Epoch 00105: val_accuracy did not improve from 0.80141\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4893 - accuracy: 0.8718 - val_loss: 0.9409 - val_accuracy: 0.7781 - lr: 0.0010\n",
      "Epoch 106/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.8727\n",
      "Epoch 00106: val_accuracy did not improve from 0.80141\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4638 - accuracy: 0.8727 - val_loss: 0.8339 - val_accuracy: 0.7949 - lr: 0.0010\n",
      "Epoch 107/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.8724\n",
      "Epoch 00107: val_accuracy did not improve from 0.80141\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4731 - accuracy: 0.8724 - val_loss: 0.8873 - val_accuracy: 0.7863 - lr: 0.0010\n",
      "Epoch 108/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.8695\n",
      "Epoch 00108: val_accuracy did not improve from 0.80141\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4892 - accuracy: 0.8695 - val_loss: 1.1259 - val_accuracy: 0.7338 - lr: 0.0010\n",
      "Epoch 109/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.8772\n",
      "Epoch 00109: val_accuracy improved from 0.80141 to 0.80303, saving model to face.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 60s 1s/step - loss: 0.4637 - accuracy: 0.8772 - val_loss: 0.8283 - val_accuracy: 0.8030 - lr: 0.0010\n",
      "Epoch 110/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8830\n",
      "Epoch 00110: val_accuracy did not improve from 0.80303\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4411 - accuracy: 0.8830 - val_loss: 1.3603 - val_accuracy: 0.7284 - lr: 0.0010\n",
      "Epoch 111/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8839\n",
      "Epoch 00111: val_accuracy did not improve from 0.80303\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4255 - accuracy: 0.8839 - val_loss: 1.0010 - val_accuracy: 0.7511 - lr: 0.0010\n",
      "Epoch 112/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4651 - accuracy: 0.8780\n",
      "Epoch 00112: val_accuracy did not improve from 0.80303\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4651 - accuracy: 0.8780 - val_loss: 0.8416 - val_accuracy: 0.7992 - lr: 0.0010\n",
      "Epoch 113/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8878\n",
      "Epoch 00113: val_accuracy did not improve from 0.80303\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.4243 - accuracy: 0.8878 - val_loss: 1.0271 - val_accuracy: 0.7608 - lr: 0.0010\n",
      "Epoch 114/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.8886\n",
      "Epoch 00114: val_accuracy did not improve from 0.80303\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4227 - accuracy: 0.8886 - val_loss: 1.0410 - val_accuracy: 0.7738 - lr: 0.0010\n",
      "Epoch 115/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8921\n",
      "Epoch 00115: val_accuracy improved from 0.80303 to 0.80357, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4094 - accuracy: 0.8921 - val_loss: 0.8744 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 116/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3933 - accuracy: 0.8961\n",
      "Epoch 00116: val_accuracy improved from 0.80357 to 0.81926, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3933 - accuracy: 0.8961 - val_loss: 0.7557 - val_accuracy: 0.8193 - lr: 0.0010\n",
      "Epoch 117/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8979\n",
      "Epoch 00117: val_accuracy did not improve from 0.81926\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3854 - accuracy: 0.8979 - val_loss: 0.9533 - val_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 118/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3910 - accuracy: 0.8979\n",
      "Epoch 00118: val_accuracy did not improve from 0.81926\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3910 - accuracy: 0.8979 - val_loss: 0.7679 - val_accuracy: 0.8139 - lr: 0.0010\n",
      "Epoch 119/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.4003 - accuracy: 0.8934\n",
      "Epoch 00119: val_accuracy did not improve from 0.81926\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.4003 - accuracy: 0.8934 - val_loss: 0.8876 - val_accuracy: 0.7938 - lr: 0.0010\n",
      "Epoch 120/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.9051\n",
      "Epoch 00120: val_accuracy did not improve from 0.81926\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3639 - accuracy: 0.9051 - val_loss: 1.0234 - val_accuracy: 0.7592 - lr: 0.0010\n",
      "Epoch 121/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8974\n",
      "Epoch 00121: val_accuracy did not improve from 0.81926\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3854 - accuracy: 0.8974 - val_loss: 0.9205 - val_accuracy: 0.8128 - lr: 0.0010\n",
      "Epoch 122/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.9021\n",
      "Epoch 00122: val_accuracy did not improve from 0.81926\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3606 - accuracy: 0.9021 - val_loss: 0.8130 - val_accuracy: 0.8166 - lr: 0.0010\n",
      "Epoch 123/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.9057\n",
      "Epoch 00123: val_accuracy improved from 0.81926 to 0.81981, saving model to face.h5\n",
      "57/57 [==============================] - 68s 1s/step - loss: 0.3702 - accuracy: 0.9057 - val_loss: 0.8070 - val_accuracy: 0.8198 - lr: 0.0010\n",
      "Epoch 124/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.9039\n",
      "Epoch 00124: val_accuracy did not improve from 0.81981\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.3625 - accuracy: 0.9039 - val_loss: 1.1555 - val_accuracy: 0.7776 - lr: 0.0010\n",
      "Epoch 125/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3305 - accuracy: 0.9122\n",
      "Epoch 00125: val_accuracy improved from 0.81981 to 0.83387, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3305 - accuracy: 0.9122 - val_loss: 0.8410 - val_accuracy: 0.8339 - lr: 0.0010\n",
      "Epoch 126/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.9003\n",
      "Epoch 00126: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3886 - accuracy: 0.9003 - val_loss: 0.9571 - val_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 127/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.9064\n",
      "Epoch 00127: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3765 - accuracy: 0.9064 - val_loss: 1.0701 - val_accuracy: 0.7819 - lr: 0.0010\n",
      "Epoch 128/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.9105\n",
      "Epoch 00128: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3482 - accuracy: 0.9105 - val_loss: 0.8005 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 129/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3222 - accuracy: 0.9181\n",
      "Epoch 00129: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3222 - accuracy: 0.9181 - val_loss: 0.8259 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 130/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.9144\n",
      "Epoch 00130: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3368 - accuracy: 0.9144 - val_loss: 0.8032 - val_accuracy: 0.8268 - lr: 0.0010\n",
      "Epoch 131/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.9177\n",
      "Epoch 00131: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3196 - accuracy: 0.9177 - val_loss: 1.3663 - val_accuracy: 0.6596 - lr: 0.0010\n",
      "Epoch 132/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3146 - accuracy: 0.9185\n",
      "Epoch 00132: val_accuracy did not improve from 0.83387\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3146 - accuracy: 0.9185 - val_loss: 0.8990 - val_accuracy: 0.7922 - lr: 0.0010\n",
      "Epoch 133/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.9149\n",
      "Epoch 00133: val_accuracy improved from 0.83387 to 0.83820, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3301 - accuracy: 0.9149 - val_loss: 0.7633 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 134/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.9195\n",
      "Epoch 00134: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3206 - accuracy: 0.9195 - val_loss: 0.9902 - val_accuracy: 0.7771 - lr: 0.0010\n",
      "Epoch 135/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3110 - accuracy: 0.9207\n",
      "Epoch 00135: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3110 - accuracy: 0.9207 - val_loss: 0.8770 - val_accuracy: 0.8133 - lr: 0.0010\n",
      "Epoch 136/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.9164\n",
      "Epoch 00136: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3264 - accuracy: 0.9164 - val_loss: 2.1183 - val_accuracy: 0.4286 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3082 - accuracy: 0.9233\n",
      "Epoch 00137: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3082 - accuracy: 0.9233 - val_loss: 0.8347 - val_accuracy: 0.8241 - lr: 0.0010\n",
      "Epoch 138/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.9233\n",
      "Epoch 00138: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2962 - accuracy: 0.9233 - val_loss: 0.7431 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 139/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.9250\n",
      "Epoch 00139: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3028 - accuracy: 0.9250 - val_loss: 0.7743 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 140/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3230 - accuracy: 0.9178\n",
      "Epoch 00140: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3230 - accuracy: 0.9178 - val_loss: 0.8797 - val_accuracy: 0.8225 - lr: 0.0010\n",
      "Epoch 141/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3120 - accuracy: 0.9219\n",
      "Epoch 00141: val_accuracy did not improve from 0.83820\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.3120 - accuracy: 0.9219 - val_loss: 0.8376 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 142/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.9284\n",
      "Epoch 00142: val_accuracy improved from 0.83820 to 0.83874, saving model to face.h5\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.2828 - accuracy: 0.9284 - val_loss: 0.7521 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 143/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9327\n",
      "Epoch 00143: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2603 - accuracy: 0.9327 - val_loss: 0.8257 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 144/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9175\n",
      "Epoch 00144: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3143 - accuracy: 0.9175 - val_loss: 0.8345 - val_accuracy: 0.8295 - lr: 0.0010\n",
      "Epoch 145/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.9196\n",
      "Epoch 00145: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.3050 - accuracy: 0.9196 - val_loss: 0.9016 - val_accuracy: 0.8128 - lr: 0.0010\n",
      "Epoch 146/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9222\n",
      "Epoch 00146: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2961 - accuracy: 0.9222 - val_loss: 0.8510 - val_accuracy: 0.8279 - lr: 0.0010\n",
      "Epoch 147/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.9323\n",
      "Epoch 00147: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2761 - accuracy: 0.9323 - val_loss: 0.8621 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 148/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.9294\n",
      "Epoch 00148: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2790 - accuracy: 0.9294 - val_loss: 0.9296 - val_accuracy: 0.8095 - lr: 0.0010\n",
      "Epoch 149/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.9269\n",
      "Epoch 00149: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2797 - accuracy: 0.9269 - val_loss: 0.8925 - val_accuracy: 0.8144 - lr: 0.0010\n",
      "Epoch 150/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.9356\n",
      "Epoch 00150: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2564 - accuracy: 0.9356 - val_loss: 0.8468 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 151/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.9342\n",
      "Epoch 00151: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.2569 - accuracy: 0.9342 - val_loss: 0.9313 - val_accuracy: 0.8122 - lr: 0.0010\n",
      "Epoch 152/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.9346\n",
      "Epoch 00152: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.2629 - accuracy: 0.9346 - val_loss: 1.0312 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 153/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9354\n",
      "Epoch 00153: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2348 - accuracy: 0.9354 - val_loss: 0.8537 - val_accuracy: 0.8258 - lr: 0.0010\n",
      "Epoch 154/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9314\n",
      "Epoch 00154: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2856 - accuracy: 0.9314 - val_loss: 0.8394 - val_accuracy: 0.8236 - lr: 0.0010\n",
      "Epoch 155/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.9383\n",
      "Epoch 00155: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2265 - accuracy: 0.9383 - val_loss: 0.9004 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 156/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.9284\n",
      "Epoch 00156: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2871 - accuracy: 0.9284 - val_loss: 0.7885 - val_accuracy: 0.8290 - lr: 0.0010\n",
      "Epoch 157/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.9287\n",
      "Epoch 00157: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2862 - accuracy: 0.9287 - val_loss: 0.8566 - val_accuracy: 0.8306 - lr: 0.0010\n",
      "Epoch 158/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9378\n",
      "Epoch 00158: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2367 - accuracy: 0.9378 - val_loss: 0.8142 - val_accuracy: 0.8344 - lr: 0.0010\n",
      "Epoch 159/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9394\n",
      "Epoch 00159: val_accuracy did not improve from 0.83874\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2394 - accuracy: 0.9394 - val_loss: 1.0948 - val_accuracy: 0.8231 - lr: 0.0010\n",
      "Epoch 160/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.9341\n",
      "Epoch 00160: val_accuracy improved from 0.83874 to 0.84416, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2610 - accuracy: 0.9341 - val_loss: 0.8233 - val_accuracy: 0.8442 - lr: 0.0010\n",
      "Epoch 161/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.9379\n",
      "Epoch 00161: val_accuracy did not improve from 0.84416\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2546 - accuracy: 0.9379 - val_loss: 0.9740 - val_accuracy: 0.8171 - lr: 0.0010\n",
      "Epoch 162/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9412\n",
      "Epoch 00162: val_accuracy did not improve from 0.84416\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.2348 - accuracy: 0.9412 - val_loss: 0.9513 - val_accuracy: 0.8090 - lr: 0.0010\n",
      "Epoch 163/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.9327\n",
      "Epoch 00163: val_accuracy did not improve from 0.84416\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2747 - accuracy: 0.9327 - val_loss: 0.9351 - val_accuracy: 0.8187 - lr: 0.0010\n",
      "Epoch 164/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.9469\n",
      "Epoch 00164: val_accuracy improved from 0.84416 to 0.84632, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2164 - accuracy: 0.9469 - val_loss: 0.8150 - val_accuracy: 0.8463 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9464\n",
      "Epoch 00165: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2062 - accuracy: 0.9464 - val_loss: 0.8576 - val_accuracy: 0.8366 - lr: 0.0010\n",
      "Epoch 166/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.9489\n",
      "Epoch 00166: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2222 - accuracy: 0.9489 - val_loss: 0.8669 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 167/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9444\n",
      "Epoch 00167: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2262 - accuracy: 0.9444 - val_loss: 0.8337 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 168/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9427\n",
      "Epoch 00168: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2063 - accuracy: 0.9427 - val_loss: 0.9208 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 169/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.9378\n",
      "Epoch 00169: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2558 - accuracy: 0.9378 - val_loss: 0.8321 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 170/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.9353\n",
      "Epoch 00170: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2609 - accuracy: 0.9353 - val_loss: 0.7375 - val_accuracy: 0.8436 - lr: 0.0010\n",
      "Epoch 171/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9437\n",
      "Epoch 00171: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2336 - accuracy: 0.9437 - val_loss: 0.9421 - val_accuracy: 0.8003 - lr: 0.0010\n",
      "Epoch 172/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9339\n",
      "Epoch 00172: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.2612 - accuracy: 0.9339 - val_loss: 0.7698 - val_accuracy: 0.8328 - lr: 0.0010\n",
      "Epoch 173/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.9452\n",
      "Epoch 00173: val_accuracy did not improve from 0.84632\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2143 - accuracy: 0.9452 - val_loss: 0.8232 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 174/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9513\n",
      "Epoch 00174: val_accuracy improved from 0.84632 to 0.85768, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2212 - accuracy: 0.9513 - val_loss: 0.7050 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 175/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.9489\n",
      "Epoch 00175: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1980 - accuracy: 0.9489 - val_loss: 0.7339 - val_accuracy: 0.8458 - lr: 0.0010\n",
      "Epoch 176/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9498\n",
      "Epoch 00176: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2063 - accuracy: 0.9498 - val_loss: 0.8638 - val_accuracy: 0.8295 - lr: 0.0010\n",
      "Epoch 177/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.9467\n",
      "Epoch 00177: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2103 - accuracy: 0.9467 - val_loss: 0.8679 - val_accuracy: 0.8285 - lr: 0.0010\n",
      "Epoch 178/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.9489\n",
      "Epoch 00178: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2129 - accuracy: 0.9489 - val_loss: 0.7335 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 179/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9496\n",
      "Epoch 00179: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2023 - accuracy: 0.9496 - val_loss: 0.8497 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Epoch 180/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9398\n",
      "Epoch 00180: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2370 - accuracy: 0.9398 - val_loss: 0.9253 - val_accuracy: 0.8295 - lr: 0.0010\n",
      "Epoch 181/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.9500\n",
      "Epoch 00181: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2137 - accuracy: 0.9500 - val_loss: 1.0716 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 182/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9489\n",
      "Epoch 00182: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.2125 - accuracy: 0.9489 - val_loss: 1.3176 - val_accuracy: 0.8312 - lr: 0.0010\n",
      "Epoch 183/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9537\n",
      "Epoch 00183: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1806 - accuracy: 0.9537 - val_loss: 0.8597 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 184/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9463\n",
      "Epoch 00184: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2216 - accuracy: 0.9463 - val_loss: 0.8881 - val_accuracy: 0.8360 - lr: 0.0010\n",
      "Epoch 185/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.9502\n",
      "Epoch 00185: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2077 - accuracy: 0.9502 - val_loss: 0.8401 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 186/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.9491\n",
      "Epoch 00186: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2083 - accuracy: 0.9491 - val_loss: 0.7627 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 187/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9474\n",
      "Epoch 00187: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2171 - accuracy: 0.9474 - val_loss: 0.7540 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 188/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.9513\n",
      "Epoch 00188: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2024 - accuracy: 0.9513 - val_loss: 0.8269 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 189/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.9420\n",
      "Epoch 00189: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2255 - accuracy: 0.9420 - val_loss: 0.8248 - val_accuracy: 0.8474 - lr: 0.0010\n",
      "Epoch 190/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2042 - accuracy: 0.9500\n",
      "Epoch 00190: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2042 - accuracy: 0.9500 - val_loss: 0.9548 - val_accuracy: 0.8225 - lr: 0.0010\n",
      "Epoch 191/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9473\n",
      "Epoch 00191: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2252 - accuracy: 0.9473 - val_loss: 0.7636 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 192/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9540\n",
      "Epoch 00192: val_accuracy did not improve from 0.85768\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1928 - accuracy: 0.9540 - val_loss: 0.8887 - val_accuracy: 0.8252 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.9565\n",
      "Epoch 00193: val_accuracy improved from 0.85768 to 0.85877, saving model to face.h5\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.1816 - accuracy: 0.9565 - val_loss: 0.6970 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Epoch 194/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9573\n",
      "Epoch 00194: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1767 - accuracy: 0.9573 - val_loss: 1.0602 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 195/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9474\n",
      "Epoch 00195: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2182 - accuracy: 0.9474 - val_loss: 0.8629 - val_accuracy: 0.8306 - lr: 0.0010\n",
      "Epoch 196/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9544\n",
      "Epoch 00196: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1954 - accuracy: 0.9544 - val_loss: 0.8343 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Epoch 197/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9601\n",
      "Epoch 00197: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1672 - accuracy: 0.9601 - val_loss: 1.0325 - val_accuracy: 0.8057 - lr: 0.0010\n",
      "Epoch 198/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9615\n",
      "Epoch 00198: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1638 - accuracy: 0.9615 - val_loss: 0.8324 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 199/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.9445\n",
      "Epoch 00199: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2387 - accuracy: 0.9445 - val_loss: 0.8347 - val_accuracy: 0.8463 - lr: 0.0010\n",
      "Epoch 200/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.9564\n",
      "Epoch 00200: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1835 - accuracy: 0.9564 - val_loss: 0.7521 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 201/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9584\n",
      "Epoch 00201: val_accuracy did not improve from 0.85877\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.1732 - accuracy: 0.9584 - val_loss: 0.8753 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 202/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.9543\n",
      "Epoch 00202: val_accuracy improved from 0.85877 to 0.86634, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1934 - accuracy: 0.9543 - val_loss: 0.7306 - val_accuracy: 0.8663 - lr: 0.0010\n",
      "Epoch 203/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9602\n",
      "Epoch 00203: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1680 - accuracy: 0.9602 - val_loss: 0.7560 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 204/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9502\n",
      "Epoch 00204: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2070 - accuracy: 0.9502 - val_loss: 0.8611 - val_accuracy: 0.8306 - lr: 0.0010\n",
      "Epoch 205/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9537\n",
      "Epoch 00205: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1815 - accuracy: 0.9537 - val_loss: 0.8819 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 206/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9521\n",
      "Epoch 00206: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1978 - accuracy: 0.9521 - val_loss: 0.8044 - val_accuracy: 0.8479 - lr: 0.0010\n",
      "Epoch 207/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9580\n",
      "Epoch 00207: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1865 - accuracy: 0.9580 - val_loss: 0.9003 - val_accuracy: 0.8193 - lr: 0.0010\n",
      "Epoch 208/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1643 - accuracy: 0.9608\n",
      "Epoch 00208: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1643 - accuracy: 0.9608 - val_loss: 0.8723 - val_accuracy: 0.8236 - lr: 0.0010\n",
      "Epoch 209/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.9624\n",
      "Epoch 00209: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1581 - accuracy: 0.9624 - val_loss: 0.7664 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Epoch 210/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9550\n",
      "Epoch 00210: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1904 - accuracy: 0.9550 - val_loss: 0.8979 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 211/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9570\n",
      "Epoch 00211: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.1790 - accuracy: 0.9570 - val_loss: 0.6965 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 212/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.9591\n",
      "Epoch 00212: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1600 - accuracy: 0.9591 - val_loss: 0.7351 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 213/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9570\n",
      "Epoch 00213: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1775 - accuracy: 0.9570 - val_loss: 0.8023 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 214/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.9543\n",
      "Epoch 00214: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1900 - accuracy: 0.9543 - val_loss: 0.7783 - val_accuracy: 0.8490 - lr: 0.0010\n",
      "Epoch 215/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9656\n",
      "Epoch 00215: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1583 - accuracy: 0.9656 - val_loss: 0.9023 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 216/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9597\n",
      "Epoch 00216: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1727 - accuracy: 0.9597 - val_loss: 0.8648 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 217/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9601\n",
      "Epoch 00217: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1699 - accuracy: 0.9601 - val_loss: 0.8139 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 218/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.9547\n",
      "Epoch 00218: val_accuracy did not improve from 0.86634\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1922 - accuracy: 0.9547 - val_loss: 1.6264 - val_accuracy: 0.7527 - lr: 0.0010\n",
      "Epoch 219/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9557\n",
      "Epoch 00219: val_accuracy improved from 0.86634 to 0.87067, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1914 - accuracy: 0.9557 - val_loss: 0.7130 - val_accuracy: 0.8707 - lr: 0.0010\n",
      "Epoch 220/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.9634\n",
      "Epoch 00220: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1506 - accuracy: 0.9634 - val_loss: 0.7205 - val_accuracy: 0.8598 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.9608\n",
      "Epoch 00221: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1910 - accuracy: 0.9608 - val_loss: 0.9586 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 222/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9535\n",
      "Epoch 00222: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1882 - accuracy: 0.9535 - val_loss: 0.8022 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 223/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.9616\n",
      "Epoch 00223: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1804 - accuracy: 0.9616 - val_loss: 0.7721 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 224/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9612\n",
      "Epoch 00224: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1685 - accuracy: 0.9612 - val_loss: 0.9404 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 225/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9612\n",
      "Epoch 00225: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1674 - accuracy: 0.9612 - val_loss: 0.8058 - val_accuracy: 0.8555 - lr: 0.0010\n",
      "Epoch 226/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9591\n",
      "Epoch 00226: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1748 - accuracy: 0.9591 - val_loss: 0.6612 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Epoch 227/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9623\n",
      "Epoch 00227: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1546 - accuracy: 0.9623 - val_loss: 0.9684 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 228/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9565\n",
      "Epoch 00228: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1800 - accuracy: 0.9565 - val_loss: 1.0610 - val_accuracy: 0.8209 - lr: 0.0010\n",
      "Epoch 229/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9675\n",
      "Epoch 00229: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1421 - accuracy: 0.9675 - val_loss: 0.9172 - val_accuracy: 0.8339 - lr: 0.0010\n",
      "Epoch 230/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9682\n",
      "Epoch 00230: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.1405 - accuracy: 0.9682 - val_loss: 0.8264 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 231/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9679\n",
      "Epoch 00231: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1265 - accuracy: 0.9679 - val_loss: 0.8046 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 232/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.9525\n",
      "Epoch 00232: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2166 - accuracy: 0.9525 - val_loss: 0.7977 - val_accuracy: 0.8479 - lr: 0.0010\n",
      "Epoch 233/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9606\n",
      "Epoch 00233: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1662 - accuracy: 0.9606 - val_loss: 1.1127 - val_accuracy: 0.8111 - lr: 0.0010\n",
      "Epoch 234/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9631\n",
      "Epoch 00234: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1608 - accuracy: 0.9631 - val_loss: 0.7329 - val_accuracy: 0.8669 - lr: 0.0010\n",
      "Epoch 235/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9675\n",
      "Epoch 00235: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1393 - accuracy: 0.9675 - val_loss: 0.7324 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Epoch 236/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9656\n",
      "Epoch 00236: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1466 - accuracy: 0.9656 - val_loss: 0.9885 - val_accuracy: 0.8279 - lr: 0.0010\n",
      "Epoch 237/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9627\n",
      "Epoch 00237: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1631 - accuracy: 0.9627 - val_loss: 0.8792 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 238/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9681\n",
      "Epoch 00238: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1302 - accuracy: 0.9681 - val_loss: 0.7763 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 239/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9641\n",
      "Epoch 00239: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1571 - accuracy: 0.9641 - val_loss: 0.7410 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 240/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.9613\n",
      "Epoch 00240: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1758 - accuracy: 0.9613 - val_loss: 0.8757 - val_accuracy: 0.8285 - lr: 0.0010\n",
      "Epoch 241/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9613\n",
      "Epoch 00241: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1641 - accuracy: 0.9613 - val_loss: 0.9137 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 242/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.9659\n",
      "Epoch 00242: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1455 - accuracy: 0.9659 - val_loss: 0.7203 - val_accuracy: 0.8642 - lr: 0.0010\n",
      "Epoch 243/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.9663\n",
      "Epoch 00243: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1460 - accuracy: 0.9663 - val_loss: 0.7604 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Epoch 244/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9606\n",
      "Epoch 00244: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1731 - accuracy: 0.9606 - val_loss: 0.7823 - val_accuracy: 0.8593 - lr: 0.0010\n",
      "Epoch 245/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9637\n",
      "Epoch 00245: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1425 - accuracy: 0.9637 - val_loss: 0.8704 - val_accuracy: 0.8544 - lr: 0.0010\n",
      "Epoch 246/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9645\n",
      "Epoch 00246: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1527 - accuracy: 0.9645 - val_loss: 1.2551 - val_accuracy: 0.7868 - lr: 0.0010\n",
      "Epoch 247/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9529\n",
      "Epoch 00247: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2102 - accuracy: 0.9529 - val_loss: 0.8270 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 248/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9568\n",
      "Epoch 00248: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1717 - accuracy: 0.9568 - val_loss: 0.8131 - val_accuracy: 0.8436 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9708\n",
      "Epoch 00249: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1308 - accuracy: 0.9708 - val_loss: 1.6101 - val_accuracy: 0.6293 - lr: 0.0010\n",
      "Epoch 250/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9654\n",
      "Epoch 00250: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1386 - accuracy: 0.9654 - val_loss: 0.7744 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 251/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9723\n",
      "Epoch 00251: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.1161 - accuracy: 0.9723 - val_loss: 1.0112 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 252/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9688\n",
      "Epoch 00252: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1518 - accuracy: 0.9688 - val_loss: 1.0536 - val_accuracy: 0.8128 - lr: 0.0010\n",
      "Epoch 253/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9632\n",
      "Epoch 00253: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1526 - accuracy: 0.9632 - val_loss: 1.0410 - val_accuracy: 0.8290 - lr: 0.0010\n",
      "Epoch 254/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9700\n",
      "Epoch 00254: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1247 - accuracy: 0.9700 - val_loss: 0.6980 - val_accuracy: 0.8593 - lr: 0.0010\n",
      "Epoch 255/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9676\n",
      "Epoch 00255: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1450 - accuracy: 0.9676 - val_loss: 0.9083 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "Epoch 256/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9626\n",
      "Epoch 00256: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1571 - accuracy: 0.9626 - val_loss: 1.0898 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Epoch 257/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9650\n",
      "Epoch 00257: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1423 - accuracy: 0.9650 - val_loss: 1.0153 - val_accuracy: 0.8506 - lr: 0.0010\n",
      "Epoch 258/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9660\n",
      "Epoch 00258: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1385 - accuracy: 0.9660 - val_loss: 0.9399 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 259/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9681\n",
      "Epoch 00259: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1458 - accuracy: 0.9681 - val_loss: 0.7959 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 260/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9704\n",
      "Epoch 00260: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1251 - accuracy: 0.9704 - val_loss: 0.7501 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 261/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9661\n",
      "Epoch 00261: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 68s 1s/step - loss: 0.1471 - accuracy: 0.9661 - val_loss: 1.1094 - val_accuracy: 0.8133 - lr: 0.0010\n",
      "Epoch 262/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9649\n",
      "Epoch 00262: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.1471 - accuracy: 0.9649 - val_loss: 0.8105 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 263/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9723\n",
      "Epoch 00263: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1096 - accuracy: 0.9723 - val_loss: 0.9093 - val_accuracy: 0.8609 - lr: 0.0010\n",
      "Epoch 264/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9710\n",
      "Epoch 00264: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1262 - accuracy: 0.9710 - val_loss: 0.7607 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 265/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9657\n",
      "Epoch 00265: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1399 - accuracy: 0.9657 - val_loss: 1.0617 - val_accuracy: 0.8366 - lr: 0.0010\n",
      "Epoch 266/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9628\n",
      "Epoch 00266: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1627 - accuracy: 0.9628 - val_loss: 0.7717 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 267/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9710\n",
      "Epoch 00267: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1202 - accuracy: 0.9710 - val_loss: 0.8788 - val_accuracy: 0.8555 - lr: 0.0010\n",
      "Epoch 268/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9731\n",
      "Epoch 00268: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1037 - accuracy: 0.9731 - val_loss: 0.8227 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 269/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9723\n",
      "Epoch 00269: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1117 - accuracy: 0.9723 - val_loss: 1.0057 - val_accuracy: 0.8447 - lr: 0.0010\n",
      "Epoch 270/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9649\n",
      "Epoch 00270: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1427 - accuracy: 0.9649 - val_loss: 0.7834 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Epoch 271/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9704\n",
      "Epoch 00271: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1341 - accuracy: 0.9704 - val_loss: 0.9030 - val_accuracy: 0.8523 - lr: 0.0010\n",
      "Epoch 272/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9703\n",
      "Epoch 00272: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1327 - accuracy: 0.9703 - val_loss: 0.8764 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 273/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9715\n",
      "Epoch 00273: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1262 - accuracy: 0.9715 - val_loss: 0.7445 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 274/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9740\n",
      "Epoch 00274: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1136 - accuracy: 0.9740 - val_loss: 0.8974 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Epoch 275/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9705\n",
      "Epoch 00275: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1342 - accuracy: 0.9705 - val_loss: 0.9494 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 276/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9672\n",
      "Epoch 00276: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1509 - accuracy: 0.9672 - val_loss: 0.7440 - val_accuracy: 0.8674 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9726\n",
      "Epoch 00277: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1299 - accuracy: 0.9726 - val_loss: 0.7095 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 278/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9758\n",
      "Epoch 00278: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1035 - accuracy: 0.9758 - val_loss: 0.8991 - val_accuracy: 0.8555 - lr: 0.0010\n",
      "Epoch 279/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9685\n",
      "Epoch 00279: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1421 - accuracy: 0.9685 - val_loss: 0.9651 - val_accuracy: 0.8323 - lr: 0.0010\n",
      "Epoch 280/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9697\n",
      "Epoch 00280: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1351 - accuracy: 0.9697 - val_loss: 0.7207 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Epoch 281/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9747\n",
      "Epoch 00281: val_accuracy did not improve from 0.87067\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1115 - accuracy: 0.9747 - val_loss: 0.8001 - val_accuracy: 0.8539 - lr: 0.0010\n",
      "Epoch 282/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9690\n",
      "Epoch 00282: val_accuracy improved from 0.87067 to 0.87392, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1280 - accuracy: 0.9690 - val_loss: 0.7384 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 283/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.9759\n",
      "Epoch 00283: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1126 - accuracy: 0.9759 - val_loss: 0.7847 - val_accuracy: 0.8539 - lr: 0.0010\n",
      "Epoch 284/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9767\n",
      "Epoch 00284: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1015 - accuracy: 0.9767 - val_loss: 0.9181 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 285/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9711\n",
      "Epoch 00285: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1132 - accuracy: 0.9711 - val_loss: 0.9136 - val_accuracy: 0.8506 - lr: 0.0010\n",
      "Epoch 286/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9601\n",
      "Epoch 00286: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1783 - accuracy: 0.9601 - val_loss: 1.1088 - val_accuracy: 0.7906 - lr: 0.0010\n",
      "Epoch 287/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.9581\n",
      "Epoch 00287: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2020 - accuracy: 0.9581 - val_loss: 0.8005 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 288/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9712\n",
      "Epoch 00288: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1154 - accuracy: 0.9712 - val_loss: 0.8303 - val_accuracy: 0.8474 - lr: 0.0010\n",
      "Epoch 289/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9721\n",
      "Epoch 00289: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1221 - accuracy: 0.9721 - val_loss: 0.9650 - val_accuracy: 0.8604 - lr: 0.0010\n",
      "Epoch 290/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9682\n",
      "Epoch 00290: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1448 - accuracy: 0.9682 - val_loss: 0.7082 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 291/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9730\n",
      "Epoch 00291: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.1349 - accuracy: 0.9730 - val_loss: 0.8494 - val_accuracy: 0.8479 - lr: 0.0010\n",
      "Epoch 292/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9747\n",
      "Epoch 00292: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1072 - accuracy: 0.9747 - val_loss: 0.8385 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 293/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9701\n",
      "Epoch 00293: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1303 - accuracy: 0.9701 - val_loss: 0.9765 - val_accuracy: 0.8366 - lr: 0.0010\n",
      "Epoch 294/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9641\n",
      "Epoch 00294: val_accuracy did not improve from 0.87392\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1631 - accuracy: 0.9641 - val_loss: 0.8759 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 295/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9733\n",
      "Epoch 00295: val_accuracy improved from 0.87392 to 0.87608, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1139 - accuracy: 0.9733 - val_loss: 0.7665 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 296/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9738\n",
      "Epoch 00296: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1108 - accuracy: 0.9738 - val_loss: 0.8662 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 297/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9710\n",
      "Epoch 00297: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1259 - accuracy: 0.9710 - val_loss: 0.9670 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 298/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9703\n",
      "Epoch 00298: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1270 - accuracy: 0.9703 - val_loss: 0.7754 - val_accuracy: 0.8631 - lr: 0.0010\n",
      "Epoch 299/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9743\n",
      "Epoch 00299: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1052 - accuracy: 0.9743 - val_loss: 0.8497 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 300/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9749\n",
      "Epoch 00300: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1104 - accuracy: 0.9749 - val_loss: 0.8073 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 301/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9752\n",
      "Epoch 00301: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0949 - accuracy: 0.9752 - val_loss: 0.9388 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 302/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9645\n",
      "Epoch 00302: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1597 - accuracy: 0.9645 - val_loss: 1.0103 - val_accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 303/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9692\n",
      "Epoch 00303: val_accuracy did not improve from 0.87608\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1176 - accuracy: 0.9692 - val_loss: 1.0122 - val_accuracy: 0.8090 - lr: 0.0010\n",
      "Epoch 304/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9777\n",
      "Epoch 00304: val_accuracy improved from 0.87608 to 0.88582, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1032 - accuracy: 0.9777 - val_loss: 0.7443 - val_accuracy: 0.8858 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9773\n",
      "Epoch 00305: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0983 - accuracy: 0.9773 - val_loss: 0.7942 - val_accuracy: 0.8539 - lr: 0.0010\n",
      "Epoch 306/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9769\n",
      "Epoch 00306: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1082 - accuracy: 0.9769 - val_loss: 0.9541 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 307/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9718\n",
      "Epoch 00307: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1281 - accuracy: 0.9718 - val_loss: 0.7609 - val_accuracy: 0.8669 - lr: 0.0010\n",
      "Epoch 308/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9700\n",
      "Epoch 00308: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1304 - accuracy: 0.9700 - val_loss: 0.9090 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 309/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9537\n",
      "Epoch 00309: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.2181 - accuracy: 0.9537 - val_loss: 0.8533 - val_accuracy: 0.8398 - lr: 0.0010\n",
      "Epoch 310/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9643\n",
      "Epoch 00310: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1566 - accuracy: 0.9643 - val_loss: 0.8058 - val_accuracy: 0.8534 - lr: 0.0010\n",
      "Epoch 311/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9721\n",
      "Epoch 00311: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.1330 - accuracy: 0.9721 - val_loss: 0.6767 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 312/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9734\n",
      "Epoch 00312: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1087 - accuracy: 0.9734 - val_loss: 0.8393 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 313/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9729\n",
      "Epoch 00313: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1236 - accuracy: 0.9729 - val_loss: 0.7556 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 314/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9785\n",
      "Epoch 00314: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0873 - accuracy: 0.9785 - val_loss: 0.7942 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 315/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9766\n",
      "Epoch 00315: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1069 - accuracy: 0.9766 - val_loss: 0.7477 - val_accuracy: 0.8615 - lr: 0.0010\n",
      "Epoch 316/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9773\n",
      "Epoch 00316: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1056 - accuracy: 0.9773 - val_loss: 0.9394 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 317/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.9715\n",
      "Epoch 00317: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1231 - accuracy: 0.9715 - val_loss: 0.8111 - val_accuracy: 0.8609 - lr: 0.0010\n",
      "Epoch 318/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9685\n",
      "Epoch 00318: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1470 - accuracy: 0.9685 - val_loss: 0.6817 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 319/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9703\n",
      "Epoch 00319: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1215 - accuracy: 0.9703 - val_loss: 0.8342 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 320/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9791\n",
      "Epoch 00320: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0874 - accuracy: 0.9791 - val_loss: 0.7113 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 321/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9744\n",
      "Epoch 00321: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1068 - accuracy: 0.9744 - val_loss: 0.6724 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 322/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9807\n",
      "Epoch 00322: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0818 - accuracy: 0.9807 - val_loss: 0.8717 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 323/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9770\n",
      "Epoch 00323: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1003 - accuracy: 0.9770 - val_loss: 0.7430 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 324/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9736\n",
      "Epoch 00324: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1221 - accuracy: 0.9736 - val_loss: 0.7599 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 325/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9738\n",
      "Epoch 00325: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1112 - accuracy: 0.9738 - val_loss: 0.8511 - val_accuracy: 0.8663 - lr: 0.0010\n",
      "Epoch 326/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9707\n",
      "Epoch 00326: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1427 - accuracy: 0.9707 - val_loss: 0.6554 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 327/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9729\n",
      "Epoch 00327: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1214 - accuracy: 0.9729 - val_loss: 0.7457 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 328/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9752\n",
      "Epoch 00328: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1092 - accuracy: 0.9752 - val_loss: 0.7261 - val_accuracy: 0.8788 - lr: 0.0010\n",
      "Epoch 329/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9689\n",
      "Epoch 00329: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1365 - accuracy: 0.9689 - val_loss: 0.9828 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 330/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.9721\n",
      "Epoch 00330: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1201 - accuracy: 0.9721 - val_loss: 0.8130 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 331/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9723\n",
      "Epoch 00331: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.1310 - accuracy: 0.9723 - val_loss: 0.7235 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 332/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9759\n",
      "Epoch 00332: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1093 - accuracy: 0.9759 - val_loss: 0.7427 - val_accuracy: 0.8782 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9763\n",
      "Epoch 00333: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1136 - accuracy: 0.9763 - val_loss: 0.8621 - val_accuracy: 0.8479 - lr: 0.0010\n",
      "Epoch 334/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9792\n",
      "Epoch 00334: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0935 - accuracy: 0.9792 - val_loss: 0.7464 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 335/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9785\n",
      "Epoch 00335: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0968 - accuracy: 0.9785 - val_loss: 0.8345 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 336/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9842\n",
      "Epoch 00336: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0686 - accuracy: 0.9842 - val_loss: 0.7785 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 337/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9802\n",
      "Epoch 00337: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0927 - accuracy: 0.9802 - val_loss: 0.9298 - val_accuracy: 0.8609 - lr: 0.0010\n",
      "Epoch 338/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9749\n",
      "Epoch 00338: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1062 - accuracy: 0.9749 - val_loss: 0.8283 - val_accuracy: 0.8663 - lr: 0.0010\n",
      "Epoch 339/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9788\n",
      "Epoch 00339: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0892 - accuracy: 0.9788 - val_loss: 0.7249 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 340/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.9816\n",
      "Epoch 00340: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0858 - accuracy: 0.9816 - val_loss: 0.7129 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 341/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9788\n",
      "Epoch 00341: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0834 - accuracy: 0.9788 - val_loss: 0.8757 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 342/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9809\n",
      "Epoch 00342: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0761 - accuracy: 0.9809 - val_loss: 0.9452 - val_accuracy: 0.8593 - lr: 0.0010\n",
      "Epoch 343/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9725\n",
      "Epoch 00343: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1295 - accuracy: 0.9725 - val_loss: 0.9546 - val_accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 344/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9769\n",
      "Epoch 00344: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0996 - accuracy: 0.9769 - val_loss: 0.7853 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 345/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9747\n",
      "Epoch 00345: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1039 - accuracy: 0.9747 - val_loss: 0.8752 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 346/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9780\n",
      "Epoch 00346: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1032 - accuracy: 0.9780 - val_loss: 0.9126 - val_accuracy: 0.8458 - lr: 0.0010\n",
      "Epoch 347/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9748\n",
      "Epoch 00347: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1147 - accuracy: 0.9748 - val_loss: 0.8489 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Epoch 348/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9744\n",
      "Epoch 00348: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1198 - accuracy: 0.9744 - val_loss: 0.9079 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 349/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9778\n",
      "Epoch 00349: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0906 - accuracy: 0.9778 - val_loss: 0.7566 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 350/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9806\n",
      "Epoch 00350: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0819 - accuracy: 0.9806 - val_loss: 0.7461 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 351/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9740\n",
      "Epoch 00351: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.1188 - accuracy: 0.9740 - val_loss: 0.8718 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Epoch 352/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.9715\n",
      "Epoch 00352: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1320 - accuracy: 0.9715 - val_loss: 1.1204 - val_accuracy: 0.8268 - lr: 0.0010\n",
      "Epoch 353/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9707\n",
      "Epoch 00353: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1358 - accuracy: 0.9707 - val_loss: 1.0179 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 354/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9792\n",
      "Epoch 00354: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0993 - accuracy: 0.9792 - val_loss: 0.8202 - val_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 355/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9749\n",
      "Epoch 00355: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0978 - accuracy: 0.9749 - val_loss: 0.7785 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 356/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9820\n",
      "Epoch 00356: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0850 - accuracy: 0.9820 - val_loss: 0.9501 - val_accuracy: 0.8469 - lr: 0.0010\n",
      "Epoch 357/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9754\n",
      "Epoch 00357: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1064 - accuracy: 0.9754 - val_loss: 0.7507 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 358/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9665\n",
      "Epoch 00358: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1458 - accuracy: 0.9665 - val_loss: 0.7895 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 359/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.9686\n",
      "Epoch 00359: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1598 - accuracy: 0.9686 - val_loss: 0.7954 - val_accuracy: 0.8615 - lr: 0.0010\n",
      "Epoch 360/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9792\n",
      "Epoch 00360: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0982 - accuracy: 0.9792 - val_loss: 0.8144 - val_accuracy: 0.8690 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9758\n",
      "Epoch 00361: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1162 - accuracy: 0.9758 - val_loss: 1.0053 - val_accuracy: 0.8420 - lr: 0.0010\n",
      "Epoch 362/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9641\n",
      "Epoch 00362: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1547 - accuracy: 0.9641 - val_loss: 0.7860 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Epoch 363/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 0.9730\n",
      "Epoch 00363: val_accuracy did not improve from 0.88582\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1312 - accuracy: 0.9730 - val_loss: 0.6839 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 364/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9715\n",
      "Epoch 00364: val_accuracy improved from 0.88582 to 0.88853, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1275 - accuracy: 0.9715 - val_loss: 0.6658 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 365/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9810\n",
      "Epoch 00365: val_accuracy did not improve from 0.88853\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.7220 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 366/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9740\n",
      "Epoch 00366: val_accuracy did not improve from 0.88853\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1272 - accuracy: 0.9740 - val_loss: 0.7484 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 367/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.9736\n",
      "Epoch 00367: val_accuracy did not improve from 0.88853\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1213 - accuracy: 0.9736 - val_loss: 0.7986 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 368/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9767\n",
      "Epoch 00368: val_accuracy improved from 0.88853 to 0.89069, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0966 - accuracy: 0.9767 - val_loss: 0.6034 - val_accuracy: 0.8907 - lr: 0.0010\n",
      "Epoch 369/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9800\n",
      "Epoch 00369: val_accuracy did not improve from 0.89069\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0811 - accuracy: 0.9800 - val_loss: 0.8048 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 370/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9799\n",
      "Epoch 00370: val_accuracy improved from 0.89069 to 0.89502, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0878 - accuracy: 0.9799 - val_loss: 0.7087 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 371/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9802\n",
      "Epoch 00371: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0841 - accuracy: 0.9802 - val_loss: 0.9508 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 372/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9803\n",
      "Epoch 00372: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0939 - accuracy: 0.9803 - val_loss: 0.7667 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 373/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9839\n",
      "Epoch 00373: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0645 - accuracy: 0.9839 - val_loss: 1.0755 - val_accuracy: 0.8485 - lr: 0.0010\n",
      "Epoch 374/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9831\n",
      "Epoch 00374: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0793 - accuracy: 0.9831 - val_loss: 0.8052 - val_accuracy: 0.8842 - lr: 0.0010\n",
      "Epoch 375/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9811\n",
      "Epoch 00375: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0833 - accuracy: 0.9811 - val_loss: 0.8247 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 376/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9745\n",
      "Epoch 00376: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1142 - accuracy: 0.9745 - val_loss: 0.8112 - val_accuracy: 0.8734 - lr: 0.0010\n",
      "Epoch 377/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.9795\n",
      "Epoch 00377: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0990 - accuracy: 0.9795 - val_loss: 0.8192 - val_accuracy: 0.8534 - lr: 0.0010\n",
      "Epoch 378/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9832\n",
      "Epoch 00378: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0841 - accuracy: 0.9832 - val_loss: 0.8213 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 379/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9850\n",
      "Epoch 00379: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0607 - accuracy: 0.9850 - val_loss: 0.9686 - val_accuracy: 0.8588 - lr: 0.0010\n",
      "Epoch 380/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9773\n",
      "Epoch 00380: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.1136 - accuracy: 0.9773 - val_loss: 0.8631 - val_accuracy: 0.8490 - lr: 0.0010\n",
      "Epoch 381/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9787\n",
      "Epoch 00381: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1008 - accuracy: 0.9787 - val_loss: 0.7170 - val_accuracy: 0.8896 - lr: 0.0010\n",
      "Epoch 382/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9802\n",
      "Epoch 00382: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0897 - accuracy: 0.9802 - val_loss: 0.8085 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 383/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9813\n",
      "Epoch 00383: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0840 - accuracy: 0.9813 - val_loss: 0.8342 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 384/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9839\n",
      "Epoch 00384: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0778 - accuracy: 0.9839 - val_loss: 0.9652 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 385/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9659\n",
      "Epoch 00385: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1685 - accuracy: 0.9659 - val_loss: 0.7506 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 386/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9741\n",
      "Epoch 00386: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1107 - accuracy: 0.9741 - val_loss: 0.7105 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 387/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9782\n",
      "Epoch 00387: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1008 - accuracy: 0.9782 - val_loss: 1.2004 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 388/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9638\n",
      "Epoch 00388: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1561 - accuracy: 0.9638 - val_loss: 0.6750 - val_accuracy: 0.8772 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9763\n",
      "Epoch 00389: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1071 - accuracy: 0.9763 - val_loss: 0.7987 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 390/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9800\n",
      "Epoch 00390: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0886 - accuracy: 0.9800 - val_loss: 0.7185 - val_accuracy: 0.8804 - lr: 0.0010\n",
      "Epoch 391/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9778\n",
      "Epoch 00391: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1142 - accuracy: 0.9778 - val_loss: 0.8271 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 392/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9752\n",
      "Epoch 00392: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1047 - accuracy: 0.9752 - val_loss: 0.7787 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Epoch 393/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9743\n",
      "Epoch 00393: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1298 - accuracy: 0.9743 - val_loss: 0.7464 - val_accuracy: 0.8707 - lr: 0.0010\n",
      "Epoch 394/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9780\n",
      "Epoch 00394: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1017 - accuracy: 0.9780 - val_loss: 0.8047 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 395/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9838\n",
      "Epoch 00395: val_accuracy did not improve from 0.89502\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0746 - accuracy: 0.9838 - val_loss: 0.7341 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 396/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9850\n",
      "Epoch 00396: val_accuracy improved from 0.89502 to 0.89556, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0692 - accuracy: 0.9850 - val_loss: 0.6552 - val_accuracy: 0.8956 - lr: 0.0010\n",
      "Epoch 397/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9816\n",
      "Epoch 00397: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0893 - accuracy: 0.9816 - val_loss: 0.7761 - val_accuracy: 0.8609 - lr: 0.0010\n",
      "Epoch 398/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9788\n",
      "Epoch 00398: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0843 - accuracy: 0.9788 - val_loss: 0.8568 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 399/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9766\n",
      "Epoch 00399: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1022 - accuracy: 0.9766 - val_loss: 0.8570 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 400/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9814\n",
      "Epoch 00400: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.0843 - accuracy: 0.9814 - val_loss: 0.7629 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 401/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9828\n",
      "Epoch 00401: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0706 - accuracy: 0.9828 - val_loss: 0.8047 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 402/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9802\n",
      "Epoch 00402: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0906 - accuracy: 0.9802 - val_loss: 1.0073 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 403/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9744\n",
      "Epoch 00403: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1206 - accuracy: 0.9744 - val_loss: 0.7809 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 404/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9722\n",
      "Epoch 00404: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1303 - accuracy: 0.9722 - val_loss: 0.8515 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 405/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9767\n",
      "Epoch 00405: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1055 - accuracy: 0.9767 - val_loss: 0.9036 - val_accuracy: 0.8561 - lr: 0.0010\n",
      "Epoch 406/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9818\n",
      "Epoch 00406: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0826 - accuracy: 0.9818 - val_loss: 0.7255 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 407/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9833\n",
      "Epoch 00407: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0788 - accuracy: 0.9833 - val_loss: 0.6996 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 408/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9827\n",
      "Epoch 00408: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0750 - accuracy: 0.9827 - val_loss: 0.9271 - val_accuracy: 0.8539 - lr: 0.0010\n",
      "Epoch 409/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9803\n",
      "Epoch 00409: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0904 - accuracy: 0.9803 - val_loss: 0.8740 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 410/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9816\n",
      "Epoch 00410: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0852 - accuracy: 0.9816 - val_loss: 0.8334 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 411/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9782\n",
      "Epoch 00411: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0972 - accuracy: 0.9782 - val_loss: 0.7305 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 412/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9785\n",
      "Epoch 00412: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0968 - accuracy: 0.9785 - val_loss: 0.7546 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 413/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9784\n",
      "Epoch 00413: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1124 - accuracy: 0.9784 - val_loss: 0.8706 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Epoch 414/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9734\n",
      "Epoch 00414: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1267 - accuracy: 0.9734 - val_loss: 0.9461 - val_accuracy: 0.8425 - lr: 0.0010\n",
      "Epoch 415/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9769\n",
      "Epoch 00415: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1098 - accuracy: 0.9769 - val_loss: 0.8185 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 416/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9806\n",
      "Epoch 00416: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0777 - accuracy: 0.9806 - val_loss: 0.6373 - val_accuracy: 0.8847 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9836\n",
      "Epoch 00417: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0709 - accuracy: 0.9836 - val_loss: 0.7077 - val_accuracy: 0.8842 - lr: 0.0010\n",
      "Epoch 418/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9839\n",
      "Epoch 00418: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0763 - accuracy: 0.9839 - val_loss: 0.6792 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 419/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9787\n",
      "Epoch 00419: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0920 - accuracy: 0.9787 - val_loss: 0.6797 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 420/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9767\n",
      "Epoch 00420: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.1006 - accuracy: 0.9767 - val_loss: 0.8442 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 421/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9788\n",
      "Epoch 00421: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0935 - accuracy: 0.9788 - val_loss: 0.7932 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Epoch 422/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.9803\n",
      "Epoch 00422: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0875 - accuracy: 0.9803 - val_loss: 0.8236 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Epoch 423/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9796\n",
      "Epoch 00423: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1009 - accuracy: 0.9796 - val_loss: 0.6878 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 424/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.9794\n",
      "Epoch 00424: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0957 - accuracy: 0.9794 - val_loss: 0.7801 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 425/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9810\n",
      "Epoch 00425: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0880 - accuracy: 0.9810 - val_loss: 0.7853 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Epoch 426/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9791\n",
      "Epoch 00426: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0948 - accuracy: 0.9791 - val_loss: 0.8356 - val_accuracy: 0.8539 - lr: 0.0010\n",
      "Epoch 427/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9822\n",
      "Epoch 00427: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0837 - accuracy: 0.9822 - val_loss: 0.7882 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Epoch 428/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9803\n",
      "Epoch 00428: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0899 - accuracy: 0.9803 - val_loss: 0.6859 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 429/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9835\n",
      "Epoch 00429: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0798 - accuracy: 0.9835 - val_loss: 0.7162 - val_accuracy: 0.8658 - lr: 0.0010\n",
      "Epoch 430/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9796\n",
      "Epoch 00430: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 68s 1s/step - loss: 0.1128 - accuracy: 0.9796 - val_loss: 0.7140 - val_accuracy: 0.8739 - lr: 0.0010\n",
      "Epoch 431/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9798\n",
      "Epoch 00431: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0920 - accuracy: 0.9798 - val_loss: 0.7153 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 432/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9778\n",
      "Epoch 00432: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1156 - accuracy: 0.9778 - val_loss: 0.7713 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 433/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9734\n",
      "Epoch 00433: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1332 - accuracy: 0.9734 - val_loss: 0.8247 - val_accuracy: 0.8544 - lr: 0.0010\n",
      "Epoch 434/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9776\n",
      "Epoch 00434: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0944 - accuracy: 0.9776 - val_loss: 0.7276 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 435/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.9813\n",
      "Epoch 00435: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0924 - accuracy: 0.9813 - val_loss: 0.9521 - val_accuracy: 0.8544 - lr: 0.0010\n",
      "Epoch 436/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9777\n",
      "Epoch 00436: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1006 - accuracy: 0.9777 - val_loss: 0.7669 - val_accuracy: 0.8696 - lr: 0.0010\n",
      "Epoch 437/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9855\n",
      "Epoch 00437: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0611 - accuracy: 0.9855 - val_loss: 0.7919 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 438/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9827\n",
      "Epoch 00438: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0825 - accuracy: 0.9827 - val_loss: 0.6950 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 439/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9831\n",
      "Epoch 00439: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0706 - accuracy: 0.9831 - val_loss: 0.7731 - val_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 440/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9844\n",
      "Epoch 00440: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.0711 - accuracy: 0.9844 - val_loss: 0.7743 - val_accuracy: 0.8669 - lr: 0.0010\n",
      "Epoch 441/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9861\n",
      "Epoch 00441: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0559 - accuracy: 0.9861 - val_loss: 0.7354 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 442/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9913\n",
      "Epoch 00442: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0447 - accuracy: 0.9913 - val_loss: 0.7659 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 443/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9860\n",
      "Epoch 00443: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0573 - accuracy: 0.9860 - val_loss: 0.9726 - val_accuracy: 0.8620 - lr: 0.0010\n",
      "Epoch 444/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9839\n",
      "Epoch 00444: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0673 - accuracy: 0.9839 - val_loss: 0.9489 - val_accuracy: 0.8782 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9840\n",
      "Epoch 00445: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0760 - accuracy: 0.9840 - val_loss: 0.7664 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 446/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9810\n",
      "Epoch 00446: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1048 - accuracy: 0.9810 - val_loss: 0.7395 - val_accuracy: 0.8734 - lr: 0.0010\n",
      "Epoch 447/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9781\n",
      "Epoch 00447: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1121 - accuracy: 0.9781 - val_loss: 0.7963 - val_accuracy: 0.8506 - lr: 0.0010\n",
      "Epoch 448/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9751\n",
      "Epoch 00448: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1184 - accuracy: 0.9751 - val_loss: 0.8213 - val_accuracy: 0.8604 - lr: 0.0010\n",
      "Epoch 449/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9732\n",
      "Epoch 00449: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1303 - accuracy: 0.9732 - val_loss: 0.8535 - val_accuracy: 0.8571 - lr: 0.0010\n",
      "Epoch 450/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9792\n",
      "Epoch 00450: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.1048 - accuracy: 0.9792 - val_loss: 0.7271 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 451/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9829\n",
      "Epoch 00451: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0745 - accuracy: 0.9829 - val_loss: 0.9814 - val_accuracy: 0.8523 - lr: 0.0010\n",
      "Epoch 452/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9820\n",
      "Epoch 00452: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0782 - accuracy: 0.9820 - val_loss: 0.7610 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 453/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9825\n",
      "Epoch 00453: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0754 - accuracy: 0.9825 - val_loss: 1.0255 - val_accuracy: 0.8442 - lr: 0.0010\n",
      "Epoch 454/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9743\n",
      "Epoch 00454: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1116 - accuracy: 0.9743 - val_loss: 0.9002 - val_accuracy: 0.8593 - lr: 0.0010\n",
      "Epoch 455/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9719\n",
      "Epoch 00455: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1382 - accuracy: 0.9719 - val_loss: 0.9922 - val_accuracy: 0.8485 - lr: 0.0010\n",
      "Epoch 456/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9776\n",
      "Epoch 00456: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1057 - accuracy: 0.9776 - val_loss: 1.0169 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 457/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9807\n",
      "Epoch 00457: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0781 - accuracy: 0.9807 - val_loss: 0.6919 - val_accuracy: 0.8837 - lr: 0.0010\n",
      "Epoch 458/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9825\n",
      "Epoch 00458: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0696 - accuracy: 0.9825 - val_loss: 1.0956 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 459/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9805\n",
      "Epoch 00459: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.8133 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 460/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9809\n",
      "Epoch 00460: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.0891 - accuracy: 0.9809 - val_loss: 1.0178 - val_accuracy: 0.8415 - lr: 0.0010\n",
      "Epoch 461/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9814\n",
      "Epoch 00461: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0912 - accuracy: 0.9814 - val_loss: 0.8649 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 462/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9842\n",
      "Epoch 00462: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0715 - accuracy: 0.9842 - val_loss: 0.6793 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 463/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9877\n",
      "Epoch 00463: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0516 - accuracy: 0.9877 - val_loss: 0.7432 - val_accuracy: 0.8815 - lr: 0.0010\n",
      "Epoch 464/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9871\n",
      "Epoch 00464: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0714 - accuracy: 0.9871 - val_loss: 0.8641 - val_accuracy: 0.8582 - lr: 0.0010\n",
      "Epoch 465/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9842\n",
      "Epoch 00465: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0703 - accuracy: 0.9842 - val_loss: 0.8827 - val_accuracy: 0.8663 - lr: 0.0010\n",
      "Epoch 466/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9842\n",
      "Epoch 00466: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0796 - accuracy: 0.9842 - val_loss: 0.7805 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 467/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9769\n",
      "Epoch 00467: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.1229 - accuracy: 0.9769 - val_loss: 0.7509 - val_accuracy: 0.8674 - lr: 0.0010\n",
      "Epoch 468/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9844\n",
      "Epoch 00468: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0664 - accuracy: 0.9844 - val_loss: 0.9209 - val_accuracy: 0.8479 - lr: 0.0010\n",
      "Epoch 469/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9814\n",
      "Epoch 00469: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0745 - accuracy: 0.9814 - val_loss: 0.7840 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Epoch 470/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9733\n",
      "Epoch 00470: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.1221 - accuracy: 0.9733 - val_loss: 0.7812 - val_accuracy: 0.8598 - lr: 0.0010\n",
      "Epoch 471/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9839\n",
      "Epoch 00471: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0758 - accuracy: 0.9839 - val_loss: 0.7378 - val_accuracy: 0.8761 - lr: 0.0010\n",
      "Epoch 472/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9862\n",
      "Epoch 00472: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0725 - accuracy: 0.9862 - val_loss: 0.8693 - val_accuracy: 0.8685 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9839\n",
      "Epoch 00473: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0698 - accuracy: 0.9839 - val_loss: 0.7880 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 474/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9844\n",
      "Epoch 00474: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0754 - accuracy: 0.9844 - val_loss: 0.9822 - val_accuracy: 0.8701 - lr: 0.0010\n",
      "Epoch 475/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9811\n",
      "Epoch 00475: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0948 - accuracy: 0.9811 - val_loss: 0.8812 - val_accuracy: 0.8626 - lr: 0.0010\n",
      "Epoch 476/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9842\n",
      "Epoch 00476: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0757 - accuracy: 0.9842 - val_loss: 0.7177 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 477/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9862\n",
      "Epoch 00477: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0536 - accuracy: 0.9862 - val_loss: 0.9031 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 478/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9849\n",
      "Epoch 00478: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0666 - accuracy: 0.9849 - val_loss: 0.8296 - val_accuracy: 0.8723 - lr: 0.0010\n",
      "Epoch 479/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9832\n",
      "Epoch 00479: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0708 - accuracy: 0.9832 - val_loss: 0.8507 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 480/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9820\n",
      "Epoch 00480: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0764 - accuracy: 0.9820 - val_loss: 0.7571 - val_accuracy: 0.8766 - lr: 0.0010\n",
      "Epoch 481/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9847\n",
      "Epoch 00481: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 66s 1s/step - loss: 0.0736 - accuracy: 0.9847 - val_loss: 0.8205 - val_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 482/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9816\n",
      "Epoch 00482: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0896 - accuracy: 0.9816 - val_loss: 1.3485 - val_accuracy: 0.7857 - lr: 0.0010\n",
      "Epoch 483/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9752\n",
      "Epoch 00483: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1209 - accuracy: 0.9752 - val_loss: 0.7844 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 484/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.9843\n",
      "Epoch 00484: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0821 - accuracy: 0.9843 - val_loss: 0.9239 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 485/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9880\n",
      "Epoch 00485: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0476 - accuracy: 0.9880 - val_loss: 0.7842 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 486/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9883\n",
      "Epoch 00486: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0450 - accuracy: 0.9883 - val_loss: 0.8108 - val_accuracy: 0.8842 - lr: 0.0010\n",
      "Epoch 487/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9767\n",
      "Epoch 00487: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1090 - accuracy: 0.9767 - val_loss: 0.8282 - val_accuracy: 0.8680 - lr: 0.0010\n",
      "Epoch 488/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9749\n",
      "Epoch 00488: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1245 - accuracy: 0.9749 - val_loss: 0.8114 - val_accuracy: 0.8647 - lr: 0.0010\n",
      "Epoch 489/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9897\n",
      "Epoch 00489: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0484 - accuracy: 0.9897 - val_loss: 0.9037 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 490/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9838\n",
      "Epoch 00490: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0743 - accuracy: 0.9838 - val_loss: 0.7774 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 491/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9866\n",
      "Epoch 00491: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0654 - accuracy: 0.9866 - val_loss: 0.8486 - val_accuracy: 0.8707 - lr: 0.0010\n",
      "Epoch 492/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9871\n",
      "Epoch 00492: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0648 - accuracy: 0.9871 - val_loss: 1.0344 - val_accuracy: 0.8463 - lr: 0.0010\n",
      "Epoch 493/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9857\n",
      "Epoch 00493: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0659 - accuracy: 0.9857 - val_loss: 0.8676 - val_accuracy: 0.8728 - lr: 0.0010\n",
      "Epoch 494/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9847\n",
      "Epoch 00494: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0764 - accuracy: 0.9847 - val_loss: 0.8969 - val_accuracy: 0.8636 - lr: 0.0010\n",
      "Epoch 495/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9827\n",
      "Epoch 00495: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0867 - accuracy: 0.9827 - val_loss: 0.7157 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 496/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0837 - accuracy: 0.9842\n",
      "Epoch 00496: val_accuracy did not improve from 0.89556\n",
      "\n",
      "Epoch 00496: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0837 - accuracy: 0.9842 - val_loss: 1.0811 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 497/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9796\n",
      "Epoch 00497: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.1077 - accuracy: 0.9796 - val_loss: 0.7376 - val_accuracy: 0.8788 - lr: 1.0000e-04\n",
      "Epoch 498/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9875\n",
      "Epoch 00498: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0569 - accuracy: 0.9875 - val_loss: 0.6871 - val_accuracy: 0.8891 - lr: 1.0000e-04\n",
      "Epoch 499/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9884\n",
      "Epoch 00499: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0479 - accuracy: 0.9884 - val_loss: 0.6589 - val_accuracy: 0.8918 - lr: 1.0000e-04\n",
      "Epoch 500/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9926\n",
      "Epoch 00500: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0363 - accuracy: 0.9926 - val_loss: 0.6751 - val_accuracy: 0.8923 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9915\n",
      "Epoch 00501: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0379 - accuracy: 0.9915 - val_loss: 0.6606 - val_accuracy: 0.8945 - lr: 1.0000e-04\n",
      "Epoch 502/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9928\n",
      "Epoch 00502: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0320 - accuracy: 0.9928 - val_loss: 0.6598 - val_accuracy: 0.8945 - lr: 1.0000e-04\n",
      "Epoch 503/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9935\n",
      "Epoch 00503: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.6726 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 504/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9928\n",
      "Epoch 00504: val_accuracy did not improve from 0.89556\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.6674 - val_accuracy: 0.8945 - lr: 1.0000e-04\n",
      "Epoch 505/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9944\n",
      "Epoch 00505: val_accuracy improved from 0.89556 to 0.89827, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.6561 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Epoch 506/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9942\n",
      "Epoch 00506: val_accuracy did not improve from 0.89827\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 0.6746 - val_accuracy: 0.8950 - lr: 1.0000e-04\n",
      "Epoch 507/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9948\n",
      "Epoch 00507: val_accuracy did not improve from 0.89827\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0235 - accuracy: 0.9948 - val_loss: 0.6748 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Epoch 508/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9942\n",
      "Epoch 00508: val_accuracy improved from 0.89827 to 0.89935, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0266 - accuracy: 0.9942 - val_loss: 0.6721 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 509/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9944\n",
      "Epoch 00509: val_accuracy improved from 0.89935 to 0.89989, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.6640 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 510/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9939\n",
      "Epoch 00510: val_accuracy did not improve from 0.89989\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0248 - accuracy: 0.9939 - val_loss: 0.6668 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Epoch 511/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9942\n",
      "Epoch 00511: val_accuracy did not improve from 0.89989\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.6677 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 512/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9946\n",
      "Epoch 00512: val_accuracy improved from 0.89989 to 0.90097, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.6685 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 513/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9949\n",
      "Epoch 00513: val_accuracy did not improve from 0.90097\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 0.6532 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 514/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9946\n",
      "Epoch 00514: val_accuracy improved from 0.90097 to 0.90260, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0195 - accuracy: 0.9946 - val_loss: 0.6679 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 515/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9961\n",
      "Epoch 00515: val_accuracy did not improve from 0.90260\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0175 - accuracy: 0.9961 - val_loss: 0.6816 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 516/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9953\n",
      "Epoch 00516: val_accuracy improved from 0.90260 to 0.90476, saving model to face.h5\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.6991 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 517/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9945\n",
      "Epoch 00517: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.7154 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 518/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9949\n",
      "Epoch 00518: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.7279 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 519/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9955\n",
      "Epoch 00519: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.7118 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 520/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 00520: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.6975 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 521/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9964\n",
      "Epoch 00521: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.6931 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 522/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9959\n",
      "Epoch 00522: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.6870 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 523/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9961\n",
      "Epoch 00523: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.6934 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 524/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9952\n",
      "Epoch 00524: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.7058 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 525/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9949\n",
      "Epoch 00525: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.7222 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 526/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9959\n",
      "Epoch 00526: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.7246 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 527/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9966\n",
      "Epoch 00527: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.7235 - val_accuracy: 0.8988 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9968\n",
      "Epoch 00528: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.7349 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 529/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9961\n",
      "Epoch 00529: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.7419 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 530/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9960\n",
      "Epoch 00530: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.7457 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 531/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9960\n",
      "Epoch 00531: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.7309 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 532/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9956\n",
      "Epoch 00532: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.7332 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 533/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 00533: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.7383 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 534/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9957\n",
      "Epoch 00534: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.7382 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 535/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9968\n",
      "Epoch 00535: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.7617 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 536/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9971\n",
      "Epoch 00536: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.7651 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 537/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9959\n",
      "Epoch 00537: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.7476 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 538/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9971\n",
      "Epoch 00538: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.7625 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 539/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9970\n",
      "Epoch 00539: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.7743 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 540/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9964\n",
      "Epoch 00540: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.7914 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 541/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9970\n",
      "Epoch 00541: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.7614 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 542/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9970\n",
      "Epoch 00542: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0125 - accuracy: 0.9970 - val_loss: 0.7787 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 543/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 00543: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.7836 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 544/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 00544: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.7894 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 545/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964\n",
      "Epoch 00545: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.7783 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 546/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 00546: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.7617 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 547/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9974\n",
      "Epoch 00547: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.7685 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 548/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 00548: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.7760 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 549/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9967\n",
      "Epoch 00549: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.7648 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 550/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9971\n",
      "Epoch 00550: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.7568 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 551/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9955\n",
      "Epoch 00551: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.7938 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 552/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9967\n",
      "Epoch 00552: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.7800 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 553/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9966\n",
      "Epoch 00553: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.7935 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 554/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9961\n",
      "Epoch 00554: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.7902 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 555/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9966\n",
      "Epoch 00555: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.7935 - val_accuracy: 0.9015 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9971\n",
      "Epoch 00556: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.7925 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 557/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9964\n",
      "Epoch 00557: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.7811 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 558/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9964\n",
      "Epoch 00558: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.7782 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 559/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9953\n",
      "Epoch 00559: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.7805 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 560/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9957\n",
      "Epoch 00560: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.7539 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 561/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 00561: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.7625 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 562/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 00562: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.7793 - val_accuracy: 0.8956 - lr: 1.0000e-04\n",
      "Epoch 563/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9971\n",
      "Epoch 00563: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.7739 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 564/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9971\n",
      "Epoch 00564: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.7814 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 565/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 00565: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.7848 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 566/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9967\n",
      "Epoch 00566: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.7787 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 567/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9972\n",
      "Epoch 00567: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.7864 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 568/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9968\n",
      "Epoch 00568: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.7838 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 569/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 00569: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.7947 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 570/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9971\n",
      "Epoch 00570: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.8034 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 571/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9970\n",
      "Epoch 00571: val_accuracy did not improve from 0.90476\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.8113 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 572/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9970\n",
      "Epoch 00572: val_accuracy improved from 0.90476 to 0.90639, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.7922 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 573/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9963\n",
      "Epoch 00573: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.7991 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 574/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9979\n",
      "Epoch 00574: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.8224 - val_accuracy: 0.8961 - lr: 1.0000e-04\n",
      "Epoch 575/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9970\n",
      "Epoch 00575: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.8307 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 576/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9967\n",
      "Epoch 00576: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.7927 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 577/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9963\n",
      "Epoch 00577: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.8015 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 578/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 00578: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.7868 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 579/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9975\n",
      "Epoch 00579: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 0.8346 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 580/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 00580: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.8213 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 581/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 00581: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.7863 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 582/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 00582: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.7899 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 583/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9974\n",
      "Epoch 00583: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.7810 - val_accuracy: 0.9042 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9961\n",
      "Epoch 00584: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.7880 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 585/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9972\n",
      "Epoch 00585: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 69s 1s/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.7958 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 586/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9966\n",
      "Epoch 00586: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 65s 1s/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.8077 - val_accuracy: 0.8966 - lr: 1.0000e-04\n",
      "Epoch 587/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9974\n",
      "Epoch 00587: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.8023 - val_accuracy: 0.8918 - lr: 1.0000e-04\n",
      "Epoch 588/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9967\n",
      "Epoch 00588: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0068 - accuracy: 0.9967 - val_loss: 0.7677 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 589/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9974\n",
      "Epoch 00589: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.7465 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 590/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 00590: val_accuracy did not improve from 0.90639\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.7704 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 591/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 00591: val_accuracy improved from 0.90639 to 0.90693, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.7402 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 592/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9971\n",
      "Epoch 00592: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.7662 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 593/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9974\n",
      "Epoch 00593: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.7895 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 594/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9978\n",
      "Epoch 00594: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.7789 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 595/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9975\n",
      "Epoch 00595: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.7762 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 596/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9977\n",
      "Epoch 00596: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.7947 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 597/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9972\n",
      "Epoch 00597: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.7840 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 598/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 00598: val_accuracy did not improve from 0.90693\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.8091 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 599/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9963\n",
      "Epoch 00599: val_accuracy improved from 0.90693 to 0.91071, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0199 - accuracy: 0.9963 - val_loss: 0.7609 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 600/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 00600: val_accuracy did not improve from 0.91071\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.7497 - val_accuracy: 0.9080 - lr: 1.0000e-04\n",
      "Epoch 601/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 00601: val_accuracy did not improve from 0.91071\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.7875 - val_accuracy: 0.9080 - lr: 1.0000e-04\n",
      "Epoch 602/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 00602: val_accuracy improved from 0.91071 to 0.91288, saving model to face.h5\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.7770 - val_accuracy: 0.9129 - lr: 1.0000e-04\n",
      "Epoch 603/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 00603: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.8064 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 604/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9981\n",
      "Epoch 00604: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.7980 - val_accuracy: 0.9080 - lr: 1.0000e-04\n",
      "Epoch 605/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 00605: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.8020 - val_accuracy: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 606/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9970\n",
      "Epoch 00606: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0136 - accuracy: 0.9970 - val_loss: 0.8339 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 607/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9974\n",
      "Epoch 00607: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.8259 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 608/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 00608: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.8418 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 609/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9968\n",
      "Epoch 00609: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.7919 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 610/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9974\n",
      "Epoch 00610: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.7728 - val_accuracy: 0.9080 - lr: 1.0000e-04\n",
      "Epoch 611/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 00611: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.7871 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 612/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9968\n",
      "Epoch 00612: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0128 - accuracy: 0.9968 - val_loss: 0.7949 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 613/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9974\n",
      "Epoch 00613: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.7969 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 614/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9968\n",
      "Epoch 00614: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.8223 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 615/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9977\n",
      "Epoch 00615: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.8150 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 616/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9970\n",
      "Epoch 00616: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.7921 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 617/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 00617: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.7954 - val_accuracy: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 618/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 00618: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.8060 - val_accuracy: 0.9102 - lr: 1.0000e-04\n",
      "Epoch 619/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 00619: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.8511 - val_accuracy: 0.9080 - lr: 1.0000e-04\n",
      "Epoch 620/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9981\n",
      "Epoch 00620: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.8485 - val_accuracy: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 621/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 00621: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.8295 - val_accuracy: 0.9129 - lr: 1.0000e-04\n",
      "Epoch 622/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9973\n",
      "Epoch 00622: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.8502 - val_accuracy: 0.9113 - lr: 1.0000e-04\n",
      "Epoch 623/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9972\n",
      "Epoch 00623: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.8266 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 624/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9977\n",
      "Epoch 00624: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.8353 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 625/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9974\n",
      "Epoch 00625: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.8231 - val_accuracy: 0.9075 - lr: 1.0000e-04\n",
      "Epoch 626/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9978\n",
      "Epoch 00626: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.8416 - val_accuracy: 0.9075 - lr: 1.0000e-04\n",
      "Epoch 627/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n",
      "Epoch 00627: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.8447 - val_accuracy: 0.9096 - lr: 1.0000e-04\n",
      "Epoch 628/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 00628: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.8057 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 629/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 00629: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.8043 - val_accuracy: 0.9096 - lr: 1.0000e-04\n",
      "Epoch 630/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9964\n",
      "Epoch 00630: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.8223 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 631/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 00631: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.7986 - val_accuracy: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 632/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9970\n",
      "Epoch 00632: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.7974 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 633/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 00633: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.8326 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 634/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 00634: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.8439 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 635/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9978\n",
      "Epoch 00635: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0112 - accuracy: 0.9978 - val_loss: 0.8502 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 636/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 00636: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.8737 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 637/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 00637: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.8382 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 638/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 00638: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.8222 - val_accuracy: 0.9091 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9967\n",
      "Epoch 00639: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.8148 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 640/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9974\n",
      "Epoch 00640: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.8216 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 641/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 00641: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.8614 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 642/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9968\n",
      "Epoch 00642: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.8514 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 643/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 00643: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.8440 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 644/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 00644: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 67s 1s/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.8370 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 645/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 00645: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.8312 - val_accuracy: 0.9075 - lr: 1.0000e-04\n",
      "Epoch 646/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9975\n",
      "Epoch 00646: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.8313 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 647/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 00647: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.8580 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 648/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9968\n",
      "Epoch 00648: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.8804 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 649/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9971\n",
      "Epoch 00649: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.8440 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 650/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9966\n",
      "Epoch 00650: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.8496 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 651/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9971\n",
      "Epoch 00651: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.8284 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 652/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 00652: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.8101 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 653/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 00653: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.8075 - val_accuracy: 0.9069 - lr: 1.0000e-04\n",
      "Epoch 654/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9978\n",
      "Epoch 00654: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.8151 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 655/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00655: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.8337 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 656/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 00656: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.8077 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 657/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 00657: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.8184 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 658/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9979\n",
      "Epoch 00658: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.8312 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 659/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 00659: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.8539 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 660/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9968\n",
      "Epoch 00660: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.8591 - val_accuracy: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 661/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9977\n",
      "Epoch 00661: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.8198 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 662/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 00662: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.9155 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 663/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 00663: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.8830 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
      "Epoch 664/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9960\n",
      "Epoch 00664: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 68s 1s/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.8613 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 665/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9968\n",
      "Epoch 00665: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.8584 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 666/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 00666: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.8325 - val_accuracy: 0.9048 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00667: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.8230 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 668/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9975\n",
      "Epoch 00668: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.8379 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 669/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9968\n",
      "Epoch 00669: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0083 - accuracy: 0.9968 - val_loss: 0.8296 - val_accuracy: 0.9064 - lr: 1.0000e-04\n",
      "Epoch 670/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00670: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.8411 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 671/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9967\n",
      "Epoch 00671: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.8557 - val_accuracy: 0.9048 - lr: 1.0000e-04\n",
      "Epoch 672/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9974\n",
      "Epoch 00672: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.8539 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 673/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9974\n",
      "Epoch 00673: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.8622 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 674/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9981\n",
      "Epoch 00674: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 68s 1s/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 0.8738 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 675/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 00675: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 67s 1s/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.9140 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 676/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9983\n",
      "Epoch 00676: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.8818 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 677/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 00677: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.8759 - val_accuracy: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 678/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 00678: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.9312 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
      "Epoch 679/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00679: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.9200 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 680/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9978\n",
      "Epoch 00680: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.8788 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 681/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00681: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.9210 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 682/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 00682: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.9133 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 683/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00683: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.8614 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 684/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9981\n",
      "Epoch 00684: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.0093 - accuracy: 0.9981 - val_loss: 0.8739 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 685/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9968\n",
      "Epoch 00685: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.8817 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
      "Epoch 686/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9978\n",
      "Epoch 00686: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.8930 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 687/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9979\n",
      "Epoch 00687: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.8538 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 688/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 00688: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.8726 - val_accuracy: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 689/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9979\n",
      "Epoch 00689: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.9439 - val_accuracy: 0.8983 - lr: 1.0000e-04\n",
      "Epoch 690/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9970\n",
      "Epoch 00690: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.8810 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 691/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9966\n",
      "Epoch 00691: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0178 - accuracy: 0.9966 - val_loss: 0.8646 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 692/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9979\n",
      "Epoch 00692: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.8563 - val_accuracy: 0.9015 - lr: 1.0000e-04\n",
      "Epoch 693/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 00693: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.8606 - val_accuracy: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 694/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 00694: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.8584 - val_accuracy: 0.9053 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 695/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9975\n",
      "Epoch 00695: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0056 - accuracy: 0.9975 - val_loss: 0.8767 - val_accuracy: 0.9053 - lr: 1.0000e-04\n",
      "Epoch 696/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9971\n",
      "Epoch 00696: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.9001 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 697/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9966\n",
      "Epoch 00697: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.8435 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 698/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9978\n",
      "Epoch 00698: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.8622 - val_accuracy: 0.9042 - lr: 1.0000e-04\n",
      "Epoch 699/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 00699: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.8591 - val_accuracy: 0.8961 - lr: 1.0000e-04\n",
      "Epoch 700/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 00700: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.8395 - val_accuracy: 0.8966 - lr: 1.0000e-04\n",
      "Epoch 701/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9982\n",
      "Epoch 00701: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.8454 - val_accuracy: 0.8988 - lr: 1.0000e-04\n",
      "Epoch 702/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 00702: val_accuracy did not improve from 0.91288\n",
      "\n",
      "Epoch 00702: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.8804 - val_accuracy: 0.9004 - lr: 1.0000e-04\n",
      "Epoch 703/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9975\n",
      "Epoch 00703: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0051 - accuracy: 0.9975 - val_loss: 0.8788 - val_accuracy: 0.9004 - lr: 1.0000e-05\n",
      "Epoch 704/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 00704: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.8724 - val_accuracy: 0.9004 - lr: 1.0000e-05\n",
      "Epoch 705/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9982\n",
      "Epoch 00705: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.8718 - val_accuracy: 0.8999 - lr: 1.0000e-05\n",
      "Epoch 706/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9967\n",
      "Epoch 00706: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.8696 - val_accuracy: 0.8994 - lr: 1.0000e-05\n",
      "Epoch 707/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 00707: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0053 - accuracy: 0.9979 - val_loss: 0.8688 - val_accuracy: 0.9004 - lr: 1.0000e-05\n",
      "Epoch 708/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9977\n",
      "Epoch 00708: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.8648 - val_accuracy: 0.9010 - lr: 1.0000e-05\n",
      "Epoch 709/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 00709: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.8666 - val_accuracy: 0.9010 - lr: 1.0000e-05\n",
      "Epoch 710/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9979\n",
      "Epoch 00710: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.8658 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Epoch 711/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 00711: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.8654 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 712/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9983\n",
      "Epoch 00712: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.8617 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 713/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9978\n",
      "Epoch 00713: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 63s 1s/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.8631 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 714/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 00714: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.8623 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 715/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971\n",
      "Epoch 00715: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.8592 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 716/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9979\n",
      "Epoch 00716: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.8569 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 717/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00717: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.8586 - val_accuracy: 0.9064 - lr: 1.0000e-05\n",
      "Epoch 718/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9974\n",
      "Epoch 00718: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.8536 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 719/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9990\n",
      "Epoch 00719: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.8520 - val_accuracy: 0.9064 - lr: 1.0000e-05\n",
      "Epoch 720/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 00720: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.8507 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 721/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 00721: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 61s 1s/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.8499 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 722/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00722: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.8516 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 723/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00723: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.8543 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 724/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 00724: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.8528 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 725/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 00725: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.8527 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 726/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9979\n",
      "Epoch 00726: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.8576 - val_accuracy: 0.9069 - lr: 1.0000e-05\n",
      "Epoch 727/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 00727: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.8582 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 728/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9978\n",
      "Epoch 00728: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.8608 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 729/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 00729: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.8578 - val_accuracy: 0.9064 - lr: 1.0000e-05\n",
      "Epoch 730/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9981\n",
      "Epoch 00730: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.8597 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 731/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 00731: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.8597 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 732/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 00732: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.8555 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 733/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9983\n",
      "Epoch 00733: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.8549 - val_accuracy: 0.9058 - lr: 1.0000e-05\n",
      "Epoch 734/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9974\n",
      "Epoch 00734: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.8492 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 735/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 00735: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.8480 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 736/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9979\n",
      "Epoch 00736: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0051 - accuracy: 0.9979 - val_loss: 0.8509 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 737/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 00737: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.8471 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 738/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9975\n",
      "Epoch 00738: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.8473 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 739/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 00739: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.8496 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 740/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 00740: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.8491 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 741/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 00741: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.8523 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 742/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9975\n",
      "Epoch 00742: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0058 - accuracy: 0.9975 - val_loss: 0.8560 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 743/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 00743: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.8551 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 744/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 00744: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.8537 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 745/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 00745: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.8564 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 746/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00746: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.8586 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 747/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9982\n",
      "Epoch 00747: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.8543 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 748/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9982\n",
      "Epoch 00748: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.8546 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 749/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 00749: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.8567 - val_accuracy: 0.9031 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9975\n",
      "Epoch 00750: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0065 - accuracy: 0.9975 - val_loss: 0.8596 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 751/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00751: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.8640 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 752/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9981\n",
      "Epoch 00752: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.8632 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 753/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 00753: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.8669 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 754/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 00754: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.8626 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 755/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 00755: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.8592 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Epoch 756/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 00756: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.8596 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Epoch 757/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 00757: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.8634 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 758/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 00758: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.8661 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 759/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 00759: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.8671 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 760/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9981\n",
      "Epoch 00760: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.8678 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 761/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9988\n",
      "Epoch 00761: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.8648 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Epoch 762/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00762: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.8683 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Epoch 763/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 00763: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.8677 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 764/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9985\n",
      "Epoch 00764: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.8692 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Epoch 765/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 00765: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.8656 - val_accuracy: 0.9015 - lr: 1.0000e-05\n",
      "Epoch 766/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9979\n",
      "Epoch 00766: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.8608 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 767/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9979\n",
      "Epoch 00767: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.8574 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 768/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9979\n",
      "Epoch 00768: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.8611 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 769/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9982\n",
      "Epoch 00769: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0039 - accuracy: 0.9982 - val_loss: 0.8616 - val_accuracy: 0.9026 - lr: 1.0000e-05\n",
      "Epoch 770/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 00770: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.8653 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 771/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 00771: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.8653 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 772/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00772: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.8638 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 773/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00773: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 62s 1s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.8635 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 774/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00774: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 70s 1s/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.8647 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 775/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9981\n",
      "Epoch 00775: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.8615 - val_accuracy: 0.9021 - lr: 1.0000e-05\n",
      "Epoch 776/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 00776: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 59s 1s/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.8578 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 777/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 00777: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.8581 - val_accuracy: 0.9042 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 00778: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.8635 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 779/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9979\n",
      "Epoch 00779: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.8697 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 780/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9979\n",
      "Epoch 00780: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.8663 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 781/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 00781: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.8655 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 782/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 00782: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.8646 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 783/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 00783: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.8624 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 784/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9978\n",
      "Epoch 00784: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0121 - accuracy: 0.9978 - val_loss: 0.8607 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 785/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00785: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.8645 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 786/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 00786: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.8630 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 787/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 00787: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.8638 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 788/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9979\n",
      "Epoch 00788: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.8609 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 789/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 00789: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.8638 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 790/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9982\n",
      "Epoch 00790: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.8612 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 791/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 00791: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.8589 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 792/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 00792: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.8569 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 793/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 00793: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.8579 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 794/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 00794: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 64s 1s/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.8635 - val_accuracy: 0.9048 - lr: 1.0000e-05\n",
      "Epoch 795/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 00795: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.8615 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 796/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9981\n",
      "Epoch 00796: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.8563 - val_accuracy: 0.9053 - lr: 1.0000e-05\n",
      "Epoch 797/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 00797: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.8563 - val_accuracy: 0.9042 - lr: 1.0000e-05\n",
      "Epoch 798/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00798: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.8585 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 799/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9979\n",
      "Epoch 00799: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.8576 - val_accuracy: 0.9037 - lr: 1.0000e-05\n",
      "Epoch 800/800\n",
      "57/57 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 00800: val_accuracy did not improve from 0.91288\n",
      "57/57 [==============================] - 60s 1s/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.8567 - val_accuracy: 0.9037 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_aug,\n",
    "                    epochs=epoch,\n",
    "                    steps_per_epoch=len(trainX)// batch_size,\n",
    "                    validation_data=(testX, testY),\n",
    "                    validation_steps=len(testX) // batch_size,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "uniform-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(testX)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(testY,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hazardous-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "purple-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  3  0]\n",
      " [ 0 52  1  0  0  1  0  0  1  0  0  0  1  0  0  0  4  1  0  1  0  0  0  0\n",
      "   1  0  0  0  0  0]\n",
      " [ 0  0 66  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1\n",
      "   0  0  0  0  0  0]\n",
      " [ 1  0  0 45  0  0  1  1  0  2  0  0  0  0  0  1  0  0  1  0  1  1  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0 54  0  0  0  0  0  2  0  0  0  2  1  0  0  0  1  0  1  0  1\n",
      "   0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 51  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0\n",
      "   0  0  0  1  0  0]\n",
      " [ 0  0  0  1  0  0 49  1  0  0  0  1  0  0  0  0  0  0  1  0  0  1  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0 60  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 50  1  0  0  0  0  0  0  0  3  0  1  0  0  0\n",
      "   0  1  2  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 66  1  2  0  1  0  0  0  0  1  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 51  0  0  0  0  0  0  4  0  1  1  0  0\n",
      "   0  0  1  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0 44  0  0  0  0  0  0  1  0  0  2  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0 59  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0 55  1  0  0  0  2  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  1  0  0  0  4 53  0  0  0  2  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  1  0  1  0  1  0 48  0  0  3  0  0  0  3\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58  0  0  0  0  0  1\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0 48  0  3  1  0  0\n",
      "   1  0  0  0  4  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  1\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  1  2  0  4  0  0  0  0  0  0  0  0  0  0 51  0  0  1\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  2  0  0  0  0  0  0  0  0  0 58  0  0\n",
      "   0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  2  0  0  0  0  1  2  1  0  1  0  1 59  0\n",
      "   0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  3  1  0  1  0  0  0  0  0 62\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
      "  61  2  0  0  0  0]\n",
      " [ 0  1  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0\n",
      "   0 61  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  1  0  0  0\n",
      "   0  0 54  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 62  0  0]\n",
      " [ 1  0  0  1  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   2  1  2  0 53  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  1  0 70]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accessible-ukraine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9036796536796536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fluid-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93        56\n",
      "           1       0.91      0.83      0.87        63\n",
      "           2       0.99      0.97      0.98        68\n",
      "           3       0.88      0.83      0.86        54\n",
      "           4       0.95      0.86      0.90        63\n",
      "           5       0.96      0.93      0.94        55\n",
      "           6       0.94      0.91      0.92        54\n",
      "           7       0.87      0.97      0.92        62\n",
      "           8       0.91      0.95      0.93        63\n",
      "           9       0.85      0.83      0.84        60\n",
      "          10       0.87      0.93      0.90        71\n",
      "          11       0.89      0.88      0.89        58\n",
      "          12       0.92      0.90      0.91        49\n",
      "          13       0.98      0.98      0.98        60\n",
      "          14       0.82      0.93      0.87        59\n",
      "          15       0.91      0.85      0.88        62\n",
      "          16       0.86      0.81      0.83        59\n",
      "          17       0.95      0.98      0.97        59\n",
      "          18       0.81      0.80      0.81        60\n",
      "          19       0.83      0.97      0.90        62\n",
      "          20       0.88      0.84      0.86        61\n",
      "          21       0.89      0.92      0.91        63\n",
      "          22       0.91      0.86      0.88        69\n",
      "          23       0.89      0.91      0.90        68\n",
      "          24       0.94      0.92      0.93        66\n",
      "          25       0.90      0.91      0.90        67\n",
      "          26       0.92      0.93      0.92        58\n",
      "          27       0.97      0.97      0.97        64\n",
      "          28       0.79      0.85      0.82        62\n",
      "          29       1.00      0.96      0.98        73\n",
      "\n",
      "    accuracy                           0.90      1848\n",
      "   macro avg       0.90      0.90      0.90      1848\n",
      "weighted avg       0.91      0.90      0.90      1848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "academic-slave",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zhangyixing', 'zhangyixing', 'zhangyixing', ..., 'zhoujielun',\n",
       "       'zhoujielun', 'zhoujielun'], dtype='<U12')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "alive-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.array(labels)\n",
    "lb = LabelEncoder()\n",
    "labels_array = lb.fit_transform(labels_array)\n",
    "labels_array_categorical = to_categorical(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "african-mission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chenqiaoen', 'chenweiting', 'duhaitao', 'guanxiaotong',\n",
       "       'houminghao', 'huangjingyu', 'jingtian', 'linxinru', 'linyoujia',\n",
       "       'liyitong', 'luhan', 'masu', 'matianyu', 'wangfei', 'wangjunkai',\n",
       "       'wangyuan', 'wuyifan', 'xuweizhou', 'yangmi', 'yangyang', 'yangzi',\n",
       "       'yuanshanshan', 'zhangruoyun', 'zhangyixing', 'zhangyuxi',\n",
       "       'zhangzifeng', 'zhengshuang', 'zhoujielun', 'zhouxun', 'zhouyumin'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.unique(lb.inverse_transform(labels_array))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "careful-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "imposed-buying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'chenqiaoen',\n",
       " 1: 'chenweiting',\n",
       " 2: 'duhaitao',\n",
       " 3: 'guanxiaotong',\n",
       " 4: 'houminghao',\n",
       " 5: 'huangjingyu',\n",
       " 6: 'jingtian',\n",
       " 7: 'linxinru',\n",
       " 8: 'linyoujia',\n",
       " 9: 'liyitong',\n",
       " 10: 'luhan',\n",
       " 11: 'masu',\n",
       " 12: 'matianyu',\n",
       " 13: 'wangfei',\n",
       " 14: 'wangjunkai',\n",
       " 15: 'wangyuan',\n",
       " 16: 'wuyifan',\n",
       " 17: 'xuweizhou',\n",
       " 18: 'yangmi',\n",
       " 19: 'yangyang',\n",
       " 20: 'yangzi',\n",
       " 21: 'yuanshanshan',\n",
       " 22: 'zhangruoyun',\n",
       " 23: 'zhangyixing',\n",
       " 24: 'zhangyuxi',\n",
       " 25: 'zhangzifeng',\n",
       " 26: 'zhengshuang',\n",
       " 27: 'zhoujielun',\n",
       " 28: 'zhouxun',\n",
       " 29: 'zhouyumin'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictA = dict(zip(np.unique(labels_array), label))\n",
    "dictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ahead-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "superior-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  3  0]\n",
      " [ 0 52  1  0  0  1  0  0  1  0  0  0  1  0  0  0  4  1  0  1  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0 66  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0]\n",
      " [ 1  0  0 45  0  0  1  1  0  2  0  0  0  0  0  1  0  0  1  0  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 54  0  0  0  0  0  2  0  0  0  2  1  0  0  0  1  0  1  0  1  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 51  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  1  0  0 49  1  0  0  0  1  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0 60  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0 50  1  0  0  0  0  0  0  0  3  0  1  0  0  0  0  1  2  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 66  1  2  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 51  0  0  0  0  0  0  4  0  1  1  0  0  0  0  1  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0 44  0  0  0  0  0  0  1  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0 59  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0 55  1  0  0  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  1  0  0  0  4 53  0  0  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  1  0  1  0  1  0 48  0  0  3  0  0  0  3  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0  0 48  0  3  1  0  0  1  0  0  0  4  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  1  2  0  4  0  0  0  0  0  0  0  0  0  0 51  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  2  0  0  0  0  0  0  0  0  0 58  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  2  0  0  0  0  1  2  1  0  1  0  1 59  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  3  1  0  1  0  0  0  0  0 62  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0 61  2  0  0  0  0]\n",
      " [ 0  1  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0 61  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  1  0  0  0  0  0 54  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 62  0  0]\n",
      " [ 1  0  0  1  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  2  1  2  0 53  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 70]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "resistant-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tender-document",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee175d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
